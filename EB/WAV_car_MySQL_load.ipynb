{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcc56d5-9b21-431c-a067-e5535f66d083",
   "metadata": {},
   "source": [
    "# WAV_car_MySQL_적재"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d188c50e-844d-4f9e-a8c3-8af54db7777e",
   "metadata": {},
   "source": [
    "## 0. Spark Session 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d6e102-c181-40a3-9ec1-dd43a83a6b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import config\n",
    "from config import DB_CONFIG, HDFS_CONFIG\n",
    "\n",
    "# MySQL JDBC 드라이버 경로\n",
    "mysql_driver_path = config.MYSQL_JDBC\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WAV_sql_load\") \\\n",
    "    .config(\"spark.hadoop.fs.defaultFS\", HDFS_CONFIG[\"defaultFS\"]) \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.memory\", \"8g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"4g\") \\\n",
    "    .config(\"spark.jars\", mysql_driver_path) \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0417d55e-aa57-4366-a53f-e7c41f4a441d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.6.13 |Anaconda, Inc.| (default, Jun  4 2021, 14:25:59) \n",
      "[GCC 7.5.0]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python version:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5cfd82",
   "metadata": {},
   "source": [
    "## 1. wav_car_horn_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eae7f07",
   "metadata": {},
   "source": [
    "### 1.1 WAV -> MFCC 변환 데이터프레임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ba7a686-6751-4d12-b382-37b5c01de0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFS에서 모든 WAV 파일 읽기\n",
    "hdfs_dir = f\"{config.HDFS_BASE_PATH}/raw_data/1.Car/1.horn_of_car\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# 🔹 UDF (User Defined Function) 정의: WAV → MFCC 변환\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # 바이너리 데이터를 메모리 파일로 변환\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipy로 샘플링 레이트 확인\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosa로 리샘플링\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=50)  # MFCC 추출\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # 평균 계산\n",
    "        return mfcc_mean.tolist()  # 리스트로 반환\n",
    "    except Exception as e:\n",
    "        return None  # 에러 발생 시 None 반환\n",
    "\n",
    "# UDF 등록\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# 🔹 파일 이름 추출 UDF 정의\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# 🔹 변환 적용\n",
    "df_mfcc = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# 🔹 배열 데이터를 개별 컬럼으로 변환\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(50)]\n",
    "for i in range(50):\n",
    "    df_mfcc = df_mfcc.withColumn(mfcc_columns[i], df_mfcc[\"mfcc_features\"][i])\n",
    "\n",
    "# 🔹 불필요한 컬럼 정리\n",
    "df_mfcc = df_mfcc.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# 🔹 결과 저장 (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"✅ MFCC 데이터가 HDFS에 저장됨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1b40303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fileName: string (nullable = true)\n",
      " |-- mfcc_1: float (nullable = true)\n",
      " |-- mfcc_2: float (nullable = true)\n",
      " |-- mfcc_3: float (nullable = true)\n",
      " |-- mfcc_4: float (nullable = true)\n",
      " |-- mfcc_5: float (nullable = true)\n",
      " |-- mfcc_6: float (nullable = true)\n",
      " |-- mfcc_7: float (nullable = true)\n",
      " |-- mfcc_8: float (nullable = true)\n",
      " |-- mfcc_9: float (nullable = true)\n",
      " |-- mfcc_10: float (nullable = true)\n",
      " |-- mfcc_11: float (nullable = true)\n",
      " |-- mfcc_12: float (nullable = true)\n",
      " |-- mfcc_13: float (nullable = true)\n",
      " |-- mfcc_14: float (nullable = true)\n",
      " |-- mfcc_15: float (nullable = true)\n",
      " |-- mfcc_16: float (nullable = true)\n",
      " |-- mfcc_17: float (nullable = true)\n",
      " |-- mfcc_18: float (nullable = true)\n",
      " |-- mfcc_19: float (nullable = true)\n",
      " |-- mfcc_20: float (nullable = true)\n",
      " |-- mfcc_21: float (nullable = true)\n",
      " |-- mfcc_22: float (nullable = true)\n",
      " |-- mfcc_23: float (nullable = true)\n",
      " |-- mfcc_24: float (nullable = true)\n",
      " |-- mfcc_25: float (nullable = true)\n",
      " |-- mfcc_26: float (nullable = true)\n",
      " |-- mfcc_27: float (nullable = true)\n",
      " |-- mfcc_28: float (nullable = true)\n",
      " |-- mfcc_29: float (nullable = true)\n",
      " |-- mfcc_30: float (nullable = true)\n",
      " |-- mfcc_31: float (nullable = true)\n",
      " |-- mfcc_32: float (nullable = true)\n",
      " |-- mfcc_33: float (nullable = true)\n",
      " |-- mfcc_34: float (nullable = true)\n",
      " |-- mfcc_35: float (nullable = true)\n",
      " |-- mfcc_36: float (nullable = true)\n",
      " |-- mfcc_37: float (nullable = true)\n",
      " |-- mfcc_38: float (nullable = true)\n",
      " |-- mfcc_39: float (nullable = true)\n",
      " |-- mfcc_40: float (nullable = true)\n",
      " |-- mfcc_41: float (nullable = true)\n",
      " |-- mfcc_42: float (nullable = true)\n",
      " |-- mfcc_43: float (nullable = true)\n",
      " |-- mfcc_44: float (nullable = true)\n",
      " |-- mfcc_45: float (nullable = true)\n",
      " |-- mfcc_46: float (nullable = true)\n",
      " |-- mfcc_47: float (nullable = true)\n",
      " |-- mfcc_48: float (nullable = true)\n",
      " |-- mfcc_49: float (nullable = true)\n",
      " |-- mfcc_50: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mfcc.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3074a197-7053-4898-a36f-bad6f8b704b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3189"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ac734",
   "metadata": {},
   "source": [
    "### 1.2 wav_car_horn_data 데이터 MySQL에 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95a020a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mfcc.createOrReplaceTempView(\"wav_car_horn50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae2609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL 쿼리 실행하여 데이터 추출\n",
    "df_mfcc = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_car_horn50\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40a5676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Config 파일에서 MySQL 연결 정보 로드\n",
    "mysql_url = f\"jdbc:mysql://{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": DB_CONFIG[\"user\"],\n",
    "    \"password\": DB_CONFIG[\"password\"],\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76085885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 MySQL로 성공적으로 적재되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# MySQL로 DataFrame 적재 (쿼리 결과가 None이 아닌 경우에만)\n",
    "if df_mfcc is not None:\n",
    "    df_mfcc.write.jdbc(url=mysql_url, table=\"wav_car_horn_data50\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"데이터가 MySQL로 성공적으로 적재되었습니다!\")\n",
    "else:\n",
    "    print(\"쿼리 결과가 없습니다. 데이터 추출이 실패했습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c0bbc",
   "metadata": {},
   "source": [
    "## 2. wav_car_siren_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a36eaa",
   "metadata": {},
   "source": [
    "### 2.1 WAV -> MFCC 변환 데이터프레임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e8f3e5-9bb3-4d10-9157-475548b2a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFS에서 모든 WAV 파일 읽기\n",
    "hdfs_dir = f\"{config.HDFS_BASE_PATH}/raw_data/1.Car/2.siren_of_car\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# 🔹 UDF (User Defined Function) 정의: WAV → MFCC 변환\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # 바이너리 데이터를 메모리 파일로 변환\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipy로 샘플링 레이트 확인\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosa로 리샘플링\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=50)  # MFCC 추출\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # 평균 계산\n",
    "        return mfcc_mean.tolist()  # 리스트로 반환\n",
    "    except Exception as e:\n",
    "        return None  # 에러 발생 시 None 반환\n",
    "\n",
    "# UDF 등록\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# 🔹 파일 이름 추출 UDF 정의\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# 🔹 변환 적용\n",
    "df_mfcc_siren_car = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# 🔹 배열 데이터를 개별 컬럼으로 변환\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(50)]\n",
    "for i in range(50):\n",
    "    df_mfcc_siren_car = df_mfcc_siren_car.withColumn(mfcc_columns[i], df_mfcc_siren_car[\"mfcc_features\"][i])\n",
    "\n",
    "# 🔹 불필요한 컬럼 정리\n",
    "df_mfcc_siren_car = df_mfcc_siren_car.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# 🔹 결과 저장 (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"✅ MFCC 데이터가 HDFS에 저장됨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ad3a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fileName: string (nullable = true)\n",
      " |-- mfcc_1: float (nullable = true)\n",
      " |-- mfcc_2: float (nullable = true)\n",
      " |-- mfcc_3: float (nullable = true)\n",
      " |-- mfcc_4: float (nullable = true)\n",
      " |-- mfcc_5: float (nullable = true)\n",
      " |-- mfcc_6: float (nullable = true)\n",
      " |-- mfcc_7: float (nullable = true)\n",
      " |-- mfcc_8: float (nullable = true)\n",
      " |-- mfcc_9: float (nullable = true)\n",
      " |-- mfcc_10: float (nullable = true)\n",
      " |-- mfcc_11: float (nullable = true)\n",
      " |-- mfcc_12: float (nullable = true)\n",
      " |-- mfcc_13: float (nullable = true)\n",
      " |-- mfcc_14: float (nullable = true)\n",
      " |-- mfcc_15: float (nullable = true)\n",
      " |-- mfcc_16: float (nullable = true)\n",
      " |-- mfcc_17: float (nullable = true)\n",
      " |-- mfcc_18: float (nullable = true)\n",
      " |-- mfcc_19: float (nullable = true)\n",
      " |-- mfcc_20: float (nullable = true)\n",
      " |-- mfcc_21: float (nullable = true)\n",
      " |-- mfcc_22: float (nullable = true)\n",
      " |-- mfcc_23: float (nullable = true)\n",
      " |-- mfcc_24: float (nullable = true)\n",
      " |-- mfcc_25: float (nullable = true)\n",
      " |-- mfcc_26: float (nullable = true)\n",
      " |-- mfcc_27: float (nullable = true)\n",
      " |-- mfcc_28: float (nullable = true)\n",
      " |-- mfcc_29: float (nullable = true)\n",
      " |-- mfcc_30: float (nullable = true)\n",
      " |-- mfcc_31: float (nullable = true)\n",
      " |-- mfcc_32: float (nullable = true)\n",
      " |-- mfcc_33: float (nullable = true)\n",
      " |-- mfcc_34: float (nullable = true)\n",
      " |-- mfcc_35: float (nullable = true)\n",
      " |-- mfcc_36: float (nullable = true)\n",
      " |-- mfcc_37: float (nullable = true)\n",
      " |-- mfcc_38: float (nullable = true)\n",
      " |-- mfcc_39: float (nullable = true)\n",
      " |-- mfcc_40: float (nullable = true)\n",
      " |-- mfcc_41: float (nullable = true)\n",
      " |-- mfcc_42: float (nullable = true)\n",
      " |-- mfcc_43: float (nullable = true)\n",
      " |-- mfcc_44: float (nullable = true)\n",
      " |-- mfcc_45: float (nullable = true)\n",
      " |-- mfcc_46: float (nullable = true)\n",
      " |-- mfcc_47: float (nullable = true)\n",
      " |-- mfcc_48: float (nullable = true)\n",
      " |-- mfcc_49: float (nullable = true)\n",
      " |-- mfcc_50: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mfcc_siren_car.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c6ca314-d717-462c-a159-9380ac3edacf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc_siren_car.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8413f14d",
   "metadata": {},
   "source": [
    "### 2.2 wav_car_siren_data 데이터 MySQL에 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84285265-04aa-43e5-b172-b1b1f40ce691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 MySQL로 성공적으로 적재되었습니다!\n"
     ]
    }
   ],
   "source": [
    "df_mfcc_siren_car.createOrReplaceTempView(\"wav_car_siren50\")\n",
    "\n",
    "# SQL 쿼리 실행하여 데이터 추출\n",
    "df_mfcc_siren_car = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_car_siren50\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Config 파일에서 MySQL 연결 정보 로드\n",
    "mysql_url = f\"jdbc:mysql://{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": DB_CONFIG[\"user\"],\n",
    "    \"password\": DB_CONFIG[\"password\"],\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# MySQL로 DataFrame 적재 (쿼리 결과가 None이 아닌 경우에만)\n",
    "if df_mfcc_siren_car is not None:\n",
    "    df_mfcc_siren_car.write.jdbc(url=mysql_url, table=\"wav_car_siren_data50\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"데이터가 MySQL로 성공적으로 적재되었습니다!\")\n",
    "else:\n",
    "    print(\"쿼리 결과가 없습니다. 데이터 추출이 실패했습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e47e3",
   "metadata": {},
   "source": [
    "## 3. wav_car_driving_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c71ea2b",
   "metadata": {},
   "source": [
    "### 3.1 WAV -> MFCC 변환 데이터프레임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91804326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import io\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType\n",
    "\n",
    "# HDFS에서 모든 WAV 파일 읽기\n",
    "hdfs_dir = f\"{config.HDFS_BASE_PATH}/raw_data/1.Car/3.driving_sound_of_car\"\n",
    "binary_df = spark.read.format(\"binaryFile\").load(hdfs_dir)\n",
    "\n",
    "# 🔹 UDF (User Defined Function) 정의: WAV → MFCC 변환\n",
    "def extract_mfcc(binary_data):\n",
    "    try:\n",
    "        audio_bytes = io.BytesIO(binary_data)  # 바이너리 데이터를 메모리 파일로 변환\n",
    "        sr, audio = wavfile.read(audio_bytes)  # scipy로 샘플링 레이트 확인\n",
    "        audio_librosa, sr_librosa = librosa.load(audio_bytes, sr=None)  # librosa로 리샘플링\n",
    "        mfcc = librosa.feature.mfcc(y=audio_librosa, sr=sr_librosa, n_mfcc=50)  # MFCC 추출\n",
    "        mfcc_mean = np.mean(mfcc, axis=1).astype(float)  # 평균 계산\n",
    "        return mfcc_mean.tolist()  # 리스트로 반환\n",
    "    except Exception as e:\n",
    "        return None  # 에러 발생 시 None 반환\n",
    "\n",
    "# UDF 등록\n",
    "mfcc_udf = udf(extract_mfcc, ArrayType(FloatType()))\n",
    "\n",
    "# 🔹 파일 이름 추출 UDF 정의\n",
    "def extract_filename(path):\n",
    "    return os.path.basename(path)\n",
    "\n",
    "filename_udf = udf(extract_filename, StringType())\n",
    "\n",
    "# 🔹 변환 적용\n",
    "df_mfcc_driving_car = binary_df \\\n",
    "    .withColumn(\"fileName\", filename_udf(binary_df[\"path\"])) \\\n",
    "    .withColumn(\"mfcc_features\", mfcc_udf(binary_df[\"content\"]))\n",
    "\n",
    "# 🔹 배열 데이터를 개별 컬럼으로 변환\n",
    "mfcc_columns = [f\"mfcc_{i+1}\" for i in range(50)]\n",
    "for i in range(50):\n",
    "    df_mfcc_driving_car = df_mfcc_driving_car.withColumn(mfcc_columns[i], df_mfcc_driving_car[\"mfcc_features\"][i])\n",
    "\n",
    "# 🔹 불필요한 컬럼 정리\n",
    "df_mfcc_driving_car = df_mfcc_driving_car.select([\"fileName\"] + mfcc_columns)\n",
    "\n",
    "# 🔹 결과 저장 (HDFS)\n",
    "# output_path = \"hdfs://localhost:9000/shared_data/mfcc_features/\"\n",
    "# df_mfcc.write.csv(output_path, header=True, mode=\"overwrite\")\n",
    "\n",
    "# print(f\"✅ MFCC 데이터가 HDFS에 저장됨: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "125919f9-b572-4065-aade-bc0434641079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fileName: string (nullable = true)\n",
      " |-- mfcc_1: float (nullable = true)\n",
      " |-- mfcc_2: float (nullable = true)\n",
      " |-- mfcc_3: float (nullable = true)\n",
      " |-- mfcc_4: float (nullable = true)\n",
      " |-- mfcc_5: float (nullable = true)\n",
      " |-- mfcc_6: float (nullable = true)\n",
      " |-- mfcc_7: float (nullable = true)\n",
      " |-- mfcc_8: float (nullable = true)\n",
      " |-- mfcc_9: float (nullable = true)\n",
      " |-- mfcc_10: float (nullable = true)\n",
      " |-- mfcc_11: float (nullable = true)\n",
      " |-- mfcc_12: float (nullable = true)\n",
      " |-- mfcc_13: float (nullable = true)\n",
      " |-- mfcc_14: float (nullable = true)\n",
      " |-- mfcc_15: float (nullable = true)\n",
      " |-- mfcc_16: float (nullable = true)\n",
      " |-- mfcc_17: float (nullable = true)\n",
      " |-- mfcc_18: float (nullable = true)\n",
      " |-- mfcc_19: float (nullable = true)\n",
      " |-- mfcc_20: float (nullable = true)\n",
      " |-- mfcc_21: float (nullable = true)\n",
      " |-- mfcc_22: float (nullable = true)\n",
      " |-- mfcc_23: float (nullable = true)\n",
      " |-- mfcc_24: float (nullable = true)\n",
      " |-- mfcc_25: float (nullable = true)\n",
      " |-- mfcc_26: float (nullable = true)\n",
      " |-- mfcc_27: float (nullable = true)\n",
      " |-- mfcc_28: float (nullable = true)\n",
      " |-- mfcc_29: float (nullable = true)\n",
      " |-- mfcc_30: float (nullable = true)\n",
      " |-- mfcc_31: float (nullable = true)\n",
      " |-- mfcc_32: float (nullable = true)\n",
      " |-- mfcc_33: float (nullable = true)\n",
      " |-- mfcc_34: float (nullable = true)\n",
      " |-- mfcc_35: float (nullable = true)\n",
      " |-- mfcc_36: float (nullable = true)\n",
      " |-- mfcc_37: float (nullable = true)\n",
      " |-- mfcc_38: float (nullable = true)\n",
      " |-- mfcc_39: float (nullable = true)\n",
      " |-- mfcc_40: float (nullable = true)\n",
      " |-- mfcc_41: float (nullable = true)\n",
      " |-- mfcc_42: float (nullable = true)\n",
      " |-- mfcc_43: float (nullable = true)\n",
      " |-- mfcc_44: float (nullable = true)\n",
      " |-- mfcc_45: float (nullable = true)\n",
      " |-- mfcc_46: float (nullable = true)\n",
      " |-- mfcc_47: float (nullable = true)\n",
      " |-- mfcc_48: float (nullable = true)\n",
      " |-- mfcc_49: float (nullable = true)\n",
      " |-- mfcc_50: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_mfcc_driving_car.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6cb0e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mfcc_driving_car.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5cb4e3",
   "metadata": {},
   "source": [
    "### 3.2 wav_car_siren_data 데이터 MySQL에 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571ee4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터가 MySQL로 성공적으로 적재되었습니다!\n"
     ]
    }
   ],
   "source": [
    "df_mfcc_driving_car.createOrReplaceTempView(\"wav_car_driving50\")\n",
    "\n",
    "# SQL 쿼리 실행하여 데이터 추출\n",
    "df_mfcc_driving_car = spark.sql(\"\"\"\n",
    "    SELECT *\n",
    "    FROM wav_car_driving50\n",
    "\"\"\")\n",
    "\n",
    "# ✅ Config 파일에서 MySQL 연결 정보 로드\n",
    "mysql_url = f\"jdbc:mysql://{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['database']}?useUnicode=true&characterEncoding=UTF-8\"\n",
    "mysql_properties = {\n",
    "    \"user\": DB_CONFIG[\"user\"],\n",
    "    \"password\": DB_CONFIG[\"password\"],\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "# MySQL로 DataFrame 적재 (쿼리 결과가 None이 아닌 경우에만)\n",
    "if df_mfcc_driving_car is not None:\n",
    "    df_mfcc_driving_car.write.jdbc(url=mysql_url, table=\"wav_car_driving_data50\", mode=\"overwrite\", properties=mysql_properties)\n",
    "    print(\"데이터가 MySQL로 성공적으로 적재되었습니다!\")\n",
    "else:\n",
    "    print(\"쿼리 결과가 없습니다. 데이터 추출이 실패했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aa3bf06-f7a9-4f95-99f0-a368189491a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d090b772-4980-41bb-9e3a-92bdd3c9aec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

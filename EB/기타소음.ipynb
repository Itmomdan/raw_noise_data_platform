{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7926c766-e106-4176-a2db-35d94993f785",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 분류 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b31494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f722e487-4466-472e-ae6a-e1a9e43d2d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d7094-d02b-46b2-a460-b12032b2ab08",
   "metadata": {},
   "source": [
    "# 데이터 준비 및 전처리\n",
    "- final_training_data_sampled_1500_ood_label.csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bccf207-e413-4cf2-abb2-a1d19ebf0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습 데이터 준비\n",
    "df = pd.read_csv(\"final_training_data_sampled_1500_ood_label.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c6611f2-2ac5-4d66-9e02-c842cc528164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9000, 51)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793a4052-596c-4fdc-a417-acbf98fec260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of           mfcc_1      mfcc_2      mfcc_3     mfcc_4     mfcc_5     mfcc_6  \\\n",
       "0    -436.866821  143.990936   74.952354  45.915867  33.583057  29.956610   \n",
       "1    -369.858307  125.310371   72.073753  50.019867  36.092926  30.252110   \n",
       "2    -453.349518  113.330528   76.104362  50.643452  42.205036  40.748249   \n",
       "3    -411.235504  116.592606   75.703476  47.744938  35.118542  29.894009   \n",
       "4    -395.125549  146.027084   81.780304  48.816242  33.849194  31.080847   \n",
       "...          ...         ...         ...        ...        ...        ...   \n",
       "8995 -170.988900  208.548900  -95.111750  31.437998 -34.982487  -3.055256   \n",
       "8996 -445.657200  170.794540   38.628956  31.480406  12.929362  33.918636   \n",
       "8997 -173.931100  225.113630 -121.169975  17.288454 -13.494496 -11.085254   \n",
       "8998 -474.502300  172.619000   35.576990  25.952785  12.924660  32.762737   \n",
       "8999 -247.981190  190.959850   -7.036764  34.192413   6.349187  12.332376   \n",
       "\n",
       "         mfcc_7     mfcc_8     mfcc_9    mfcc_10  ...   mfcc_42   mfcc_43  \\\n",
       "0     26.838007  20.699930   5.734432  -5.188647  ...  0.621984  2.390124   \n",
       "1     26.472021  20.862949   7.156805  -3.059122  ...  0.209663  1.286814   \n",
       "2     35.761971  23.395164  11.045970   5.779365  ...  0.150447 -0.024921   \n",
       "3     26.577066  19.005384   6.743745  -2.823582  ... -0.908139  0.664720   \n",
       "4     28.315842  19.993208   5.521650  -3.929691  ... -0.717036  0.107550   \n",
       "...         ...        ...        ...        ...  ...       ...       ...   \n",
       "8995   1.168493 -20.571062  11.436257 -18.400883  ... -2.387195 -0.608034   \n",
       "8996  26.096716  28.349243   3.026161  -2.493732  ...  0.871266  1.258076   \n",
       "8997  -3.848992 -13.637547   9.479078 -23.499775  ... -4.868050  0.386600   \n",
       "8998  22.887897  35.366700   1.870371  -2.310633  ...  1.612635  1.285862   \n",
       "8999  -0.919341   8.426827  -3.560750   5.375006  ... -1.757113 -0.504500   \n",
       "\n",
       "       mfcc_44   mfcc_45   mfcc_46   mfcc_47   mfcc_48   mfcc_49   mfcc_50  \\\n",
       "0     1.093027 -0.793136 -0.816981  0.852164  1.310620  0.430673 -1.070722   \n",
       "1     1.113936  1.121534  1.029903  1.475248  1.835722  0.796364  0.268943   \n",
       "2     0.198790  0.637822  0.491276 -0.280820 -1.356595 -2.225216 -2.226065   \n",
       "3     0.638030  0.245853  0.599790  0.916136  0.060173 -1.450863 -2.059958   \n",
       "4    -0.071472  0.587501  0.518218  1.213491  1.460647  0.447718  0.402936   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "8995 -4.351969 -0.638857 -3.493637 -2.589549 -1.401939 -3.672604 -0.555998   \n",
       "8996  4.152141  3.298011 -1.357741  0.733067  0.738750 -1.288843 -0.883696   \n",
       "8997 -0.154787 -1.465440  1.555848 -0.959064  1.466251 -2.061570 -0.325558   \n",
       "8998  3.874604  2.885825 -2.058639  0.857671  0.667728 -0.343715  0.680497   \n",
       "8999 -0.598234 -1.930331 -0.755940 -0.770002  0.885600 -0.470559 -2.394865   \n",
       "\n",
       "      category_03  \n",
       "0             항타기  \n",
       "1             항타기  \n",
       "2             항타기  \n",
       "3             항타기  \n",
       "4             항타기  \n",
       "...           ...  \n",
       "8995        차량주행음  \n",
       "8996        차량주행음  \n",
       "8997        차량주행음  \n",
       "8998        차량주행음  \n",
       "8999        차량주행음  \n",
       "\n",
       "[9000 rows x 51 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c448cb8d-1917-46c5-82fa-90d5f06e14be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량사이렌     1500\n",
       "이륜차경적     1500\n",
       "이륜차주행음    1500\n",
       "차량경적      1500\n",
       "차량주행음     1500\n",
       "개          250\n",
       "공구         250\n",
       "항타기        250\n",
       "고양이        250\n",
       "콘크리트펌프     250\n",
       "발전기        250\n",
       "Name: category_03, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category_03'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8308502d-9670-4b08-b69b-d8215ad47bda",
   "metadata": {},
   "source": [
    "# 소음 카테고리 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e54da68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소음 카테고리 변환 함수\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values  # MFCC 특징 값\n",
    "y = df['label'].values       # 레이블\n",
    "\n",
    "# 레이블 인코딩 (문자 → 숫자)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)  # One-hot 인코딩\n",
    "\n",
    "# 데이터셋 분할 (훈련:테스트 = 80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# CNN 입력 형태로 변환 (3D 텐서: 샘플 수 x 시간 축 x 특징 수)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d880a78-41ae-45c3-8d5c-8bf150f26b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량사이렌     1500\n",
       "기타소음      1500\n",
       "이륜차경적     1500\n",
       "이륜차주행음    1500\n",
       "차량경적      1500\n",
       "차량주행음     1500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99bd144-7474-4715-b7d7-c63b75b4b493",
   "metadata": {},
   "source": [
    "# 모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b410af-f7c3-49e4-84e0-51c07d1a9fcc",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef6939f1-4285-4765-8f19-219a246dd0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN 모델 정의\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Conv1D(128, kernel_size=3, activation='relu'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(y_categorical.shape[1], activation='softmax')  # 출력층 (카테고리 수만큼 출력)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ed9bb7d-d678-4942-89f4-ed400b1f0471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "451/451 [==============================] - 3s 6ms/step - loss: 0.8353 - accuracy: 0.7090 - val_loss: 0.4207 - val_accuracy: 0.8480\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 3s 6ms/step - loss: 0.4634 - accuracy: 0.8246 - val_loss: 0.3068 - val_accuracy: 0.8946\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 3s 6ms/step - loss: 0.3797 - accuracy: 0.8584 - val_loss: 0.2581 - val_accuracy: 0.9079\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.3400 - accuracy: 0.8744 - val_loss: 0.2460 - val_accuracy: 0.9065\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.3126 - accuracy: 0.8885 - val_loss: 0.2271 - val_accuracy: 0.9168\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2877 - accuracy: 0.8982 - val_loss: 0.2178 - val_accuracy: 0.9265\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2680 - accuracy: 0.9012 - val_loss: 0.2047 - val_accuracy: 0.9212\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2570 - accuracy: 0.9084 - val_loss: 0.1922 - val_accuracy: 0.9293\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2349 - accuracy: 0.9156 - val_loss: 0.1769 - val_accuracy: 0.9351\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2262 - accuracy: 0.9210 - val_loss: 0.1936 - val_accuracy: 0.9329\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2206 - accuracy: 0.9208 - val_loss: 0.1763 - val_accuracy: 0.9354\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2153 - accuracy: 0.9223 - val_loss: 0.1698 - val_accuracy: 0.9393\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.2051 - accuracy: 0.9245 - val_loss: 0.1688 - val_accuracy: 0.9373\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1946 - accuracy: 0.9302 - val_loss: 0.1825 - val_accuracy: 0.9318\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1844 - accuracy: 0.9327 - val_loss: 0.1648 - val_accuracy: 0.9390\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1940 - accuracy: 0.9288 - val_loss: 0.1683 - val_accuracy: 0.9404\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1839 - accuracy: 0.9319 - val_loss: 0.1585 - val_accuracy: 0.9420\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1723 - accuracy: 0.9355 - val_loss: 0.1846 - val_accuracy: 0.9318\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1800 - accuracy: 0.9343 - val_loss: 0.1726 - val_accuracy: 0.9426\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1599 - accuracy: 0.9403 - val_loss: 0.1562 - val_accuracy: 0.9434\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1595 - accuracy: 0.9405 - val_loss: 0.1640 - val_accuracy: 0.9434\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1681 - accuracy: 0.9395 - val_loss: 0.1578 - val_accuracy: 0.9467\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1539 - accuracy: 0.9414 - val_loss: 0.1492 - val_accuracy: 0.9445\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1565 - accuracy: 0.9425 - val_loss: 0.1594 - val_accuracy: 0.9423\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1567 - accuracy: 0.9423 - val_loss: 0.1577 - val_accuracy: 0.9437\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1460 - accuracy: 0.9467 - val_loss: 0.1539 - val_accuracy: 0.9426\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1443 - accuracy: 0.9464 - val_loss: 0.1473 - val_accuracy: 0.9490\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1364 - accuracy: 0.9488 - val_loss: 0.1532 - val_accuracy: 0.9479\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1397 - accuracy: 0.9497 - val_loss: 0.1637 - val_accuracy: 0.9417\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 2s 5ms/step - loss: 0.1421 - accuracy: 0.9468 - val_loss: 0.1605 - val_accuracy: 0.9459\n",
      "113/113 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9459\n",
      "Accuracy: 0.9459\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.96      0.92      0.94       373\n",
      "       이륜차경적       0.98      0.95      0.97       912\n",
      "      이륜차주행음       0.93      0.95      0.94       947\n",
      "        차량경적       0.92      0.97      0.94       638\n",
      "       차량사이렌       0.98      0.95      0.96       398\n",
      "       차량주행음       0.87      0.90      0.88       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.94      0.94      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[345   4  15   2   6   1]\n",
      " [  0 866   3  43   0   0]\n",
      " [ 10   1 902   0   0  34]\n",
      " [  2   9   8 616   2   1]\n",
      " [  3   0   5   3 378   9]\n",
      " [  0   0  32   2   0 303]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 테스트 정확도 출력\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 예측된 클래스 인덱스\n",
    "y_true_classes = np.argmax(y_test, axis=1)  # 실제 클래스 인덱스\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86ff2ab9-b827-4f95-9002-48a342848c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 cnn_model_6classfication.h5 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('cnn_model_6classfication.h5')\n",
    "print(\"모델이 cnn_model_6classfication.h5 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2450d97-c64c-4dc0-ad4f-a5f8d227a1ea",
   "metadata": {},
   "source": [
    "### 성능 개선\n",
    "- 배치 정규화 (Batch Normalisation) 레이어 Conv1D 와 Dense 추가\n",
    "- 앙상블 기법 적용\n",
    "- ReduceROnPlateau 콜백 사용 \n",
    "- 모델 구조 함수화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5a581fe-7609-46c3-9938-b440534101d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.6533 - accuracy: 0.7648 - val_loss: 0.3348 - val_accuracy: 0.8810\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.4194 - accuracy: 0.8479 - val_loss: 0.2756 - val_accuracy: 0.9021\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 5s 11ms/step - loss: 0.3585 - accuracy: 0.8683 - val_loss: 0.2494 - val_accuracy: 0.9054\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3247 - accuracy: 0.8846 - val_loss: 0.2151 - val_accuracy: 0.9232\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2960 - accuracy: 0.8931 - val_loss: 0.2529 - val_accuracy: 0.9090\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2791 - accuracy: 0.8998 - val_loss: 0.2096 - val_accuracy: 0.9234\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2646 - accuracy: 0.9038 - val_loss: 0.2070 - val_accuracy: 0.9234\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2460 - accuracy: 0.9093 - val_loss: 0.1879 - val_accuracy: 0.9312\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2404 - accuracy: 0.9128 - val_loss: 0.1731 - val_accuracy: 0.9379\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2319 - accuracy: 0.9140 - val_loss: 0.1764 - val_accuracy: 0.9379\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2243 - accuracy: 0.9189 - val_loss: 0.1721 - val_accuracy: 0.9326\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2130 - accuracy: 0.9227 - val_loss: 0.1722 - val_accuracy: 0.9420\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2131 - accuracy: 0.9244 - val_loss: 0.1681 - val_accuracy: 0.9406\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2090 - accuracy: 0.9233 - val_loss: 0.1791 - val_accuracy: 0.9351\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1992 - accuracy: 0.9284 - val_loss: 0.1735 - val_accuracy: 0.9370\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2003 - accuracy: 0.9272 - val_loss: 0.1621 - val_accuracy: 0.9398\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1919 - accuracy: 0.9299 - val_loss: 0.1472 - val_accuracy: 0.9454\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1912 - accuracy: 0.9307 - val_loss: 0.1575 - val_accuracy: 0.9451\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1834 - accuracy: 0.9309 - val_loss: 0.1574 - val_accuracy: 0.9426\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1781 - accuracy: 0.9351 - val_loss: 0.1591 - val_accuracy: 0.9456\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1685 - accuracy: 0.9394 - val_loss: 0.1514 - val_accuracy: 0.9442\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1670 - accuracy: 0.9381 - val_loss: 0.1453 - val_accuracy: 0.9467\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1674 - accuracy: 0.9378 - val_loss: 0.1467 - val_accuracy: 0.9470\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1673 - accuracy: 0.9393 - val_loss: 0.1479 - val_accuracy: 0.9473\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1600 - accuracy: 0.9401 - val_loss: 0.1454 - val_accuracy: 0.9515\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1500 - accuracy: 0.9451 - val_loss: 0.1520 - val_accuracy: 0.9479\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1533 - accuracy: 0.9449 - val_loss: 0.1501 - val_accuracy: 0.9495\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1380 - accuracy: 0.9499 - val_loss: 0.1411 - val_accuracy: 0.9517\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1361 - accuracy: 0.9520 - val_loss: 0.1424 - val_accuracy: 0.9492\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1328 - accuracy: 0.9517 - val_loss: 0.1381 - val_accuracy: 0.9520\n",
      "Training model 2/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.6462 - accuracy: 0.7692 - val_loss: 0.3421 - val_accuracy: 0.8766\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.4109 - accuracy: 0.8491 - val_loss: 0.3320 - val_accuracy: 0.8718\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3544 - accuracy: 0.8719 - val_loss: 0.2476 - val_accuracy: 0.9065\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3178 - accuracy: 0.8865 - val_loss: 0.2266 - val_accuracy: 0.9118\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2915 - accuracy: 0.8925 - val_loss: 0.2156 - val_accuracy: 0.9223\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2751 - accuracy: 0.8983 - val_loss: 0.2038 - val_accuracy: 0.9223\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2578 - accuracy: 0.9049 - val_loss: 0.1957 - val_accuracy: 0.9279\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2400 - accuracy: 0.9115 - val_loss: 0.1756 - val_accuracy: 0.9343\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2390 - accuracy: 0.9133 - val_loss: 0.1748 - val_accuracy: 0.9351\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2245 - accuracy: 0.9185 - val_loss: 0.1573 - val_accuracy: 0.9426\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2274 - accuracy: 0.9175 - val_loss: 0.1701 - val_accuracy: 0.9404\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2150 - accuracy: 0.9206 - val_loss: 0.1701 - val_accuracy: 0.9401\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2102 - accuracy: 0.9224 - val_loss: 0.1565 - val_accuracy: 0.9445\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2052 - accuracy: 0.9244 - val_loss: 0.1580 - val_accuracy: 0.9456\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1991 - accuracy: 0.9271 - val_loss: 0.1552 - val_accuracy: 0.9412\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1854 - accuracy: 0.9317 - val_loss: 0.1535 - val_accuracy: 0.9434\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1807 - accuracy: 0.9331 - val_loss: 0.1528 - val_accuracy: 0.9459\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1790 - accuracy: 0.9337 - val_loss: 0.1472 - val_accuracy: 0.9498\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1739 - accuracy: 0.9350 - val_loss: 0.1496 - val_accuracy: 0.9481\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1748 - accuracy: 0.9367 - val_loss: 0.1558 - val_accuracy: 0.9434\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1720 - accuracy: 0.9385 - val_loss: 0.1431 - val_accuracy: 0.9503\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1664 - accuracy: 0.9385 - val_loss: 0.1485 - val_accuracy: 0.9495\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1589 - accuracy: 0.9397 - val_loss: 0.1631 - val_accuracy: 0.9415\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1616 - accuracy: 0.9383 - val_loss: 0.1439 - val_accuracy: 0.9484\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1564 - accuracy: 0.9420 - val_loss: 0.1545 - val_accuracy: 0.9479\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1600 - accuracy: 0.9402 - val_loss: 0.1439 - val_accuracy: 0.9490\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1410 - accuracy: 0.9460 - val_loss: 0.1387 - val_accuracy: 0.9537\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1275 - accuracy: 0.9518 - val_loss: 0.1431 - val_accuracy: 0.9503\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1318 - accuracy: 0.9505 - val_loss: 0.1446 - val_accuracy: 0.9498\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1275 - accuracy: 0.9535 - val_loss: 0.1436 - val_accuracy: 0.9509\n",
      "Training model 3/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.6376 - accuracy: 0.7713 - val_loss: 0.3297 - val_accuracy: 0.8793\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4218 - accuracy: 0.8439 - val_loss: 0.2853 - val_accuracy: 0.8926\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3607 - accuracy: 0.8672 - val_loss: 0.2527 - val_accuracy: 0.9040\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3305 - accuracy: 0.8815 - val_loss: 0.2494 - val_accuracy: 0.9074\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2954 - accuracy: 0.8945 - val_loss: 0.2452 - val_accuracy: 0.9132\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2858 - accuracy: 0.8962 - val_loss: 0.2078 - val_accuracy: 0.9234\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2710 - accuracy: 0.9043 - val_loss: 0.2158 - val_accuracy: 0.9207\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2558 - accuracy: 0.9070 - val_loss: 0.1985 - val_accuracy: 0.9240\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2428 - accuracy: 0.9104 - val_loss: 0.1806 - val_accuracy: 0.9348\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2425 - accuracy: 0.9101 - val_loss: 0.1746 - val_accuracy: 0.9373\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2319 - accuracy: 0.9161 - val_loss: 0.1767 - val_accuracy: 0.9370\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2197 - accuracy: 0.9197 - val_loss: 0.1753 - val_accuracy: 0.9362\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2105 - accuracy: 0.9247 - val_loss: 0.1683 - val_accuracy: 0.9348\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2167 - accuracy: 0.9218 - val_loss: 0.1623 - val_accuracy: 0.9415\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2016 - accuracy: 0.9265 - val_loss: 0.1632 - val_accuracy: 0.9379\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1974 - accuracy: 0.9274 - val_loss: 0.1602 - val_accuracy: 0.9420\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1941 - accuracy: 0.9291 - val_loss: 0.1853 - val_accuracy: 0.9287\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1885 - accuracy: 0.9333 - val_loss: 0.1609 - val_accuracy: 0.9398\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1877 - accuracy: 0.9317 - val_loss: 0.1458 - val_accuracy: 0.9490\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1884 - accuracy: 0.9335 - val_loss: 0.1496 - val_accuracy: 0.9451\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1760 - accuracy: 0.9363 - val_loss: 0.1645 - val_accuracy: 0.9384\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1753 - accuracy: 0.9365 - val_loss: 0.1465 - val_accuracy: 0.9459\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1658 - accuracy: 0.9376 - val_loss: 0.1550 - val_accuracy: 0.9454\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1707 - accuracy: 0.9398 - val_loss: 0.1521 - val_accuracy: 0.9381\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1479 - accuracy: 0.9460 - val_loss: 0.1434 - val_accuracy: 0.9479\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1430 - accuracy: 0.9461 - val_loss: 0.1383 - val_accuracy: 0.9473\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1357 - accuracy: 0.9508 - val_loss: 0.1424 - val_accuracy: 0.9481\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1423 - accuracy: 0.9466 - val_loss: 0.1393 - val_accuracy: 0.9498\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1313 - accuracy: 0.9521 - val_loss: 0.1396 - val_accuracy: 0.9492\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1322 - accuracy: 0.9530 - val_loss: 0.1413 - val_accuracy: 0.9476\n",
      "Ensemble Accuracy: 0.9528\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.97      0.95      0.96       373\n",
      "       이륜차경적       0.98      0.95      0.97       912\n",
      "      이륜차주행음       0.95      0.96      0.95       947\n",
      "        차량경적       0.93      0.95      0.94       638\n",
      "       차량사이렌       0.98      0.96      0.97       398\n",
      "       차량주행음       0.88      0.94      0.91       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.95      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[355   1   9   1   4   3]\n",
      " [  0 869   2  41   0   0]\n",
      " [  7   0 905   0   2  33]\n",
      " [  2  16  11 607   1   1]\n",
      " [  2   0   3   2 383   8]\n",
      " [  0   0  19   1   1 316]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비 (기존 코드와 동일)\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 개선된 CNN 모델 정의\n",
    "def create_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(y_categorical.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "def create_ensemble(num_models=3):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = create_model()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble = create_ensemble()\n",
    "\n",
    "# 학습률 스케줄링\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 모델 학습\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble):\n",
    "    print(f\"Training model {i+1}/{len(ensemble)}\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), callbacks=[reduce_lr])\n",
    "    histories.append(history)\n",
    "\n",
    "# 앙상블 예측\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측\n",
    "y_pred_ensemble = ensemble_predict(ensemble, X_test)\n",
    "y_pred_classes = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa7d6b35-e4bf-43a7-96bf-325ed92a19e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 updated_cnn_model_6classfication.h5 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('updated_cnn_model_6classfication.h5')\n",
    "print(\"모델이 updated_cnn_model_6classfication.h5 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "162f1311-650a-4f68-868f-7c2496d3ee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 50, 1)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 48, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 22, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 22, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 11, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1408)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               180352    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 774       \n",
      "=================================================================\n",
      "Total params: 207,366\n",
      "Trainable params: 206,726\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Loaded Model Accuracy: 0.9476\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.97      0.93      0.95       373\n",
      "       이륜차경적       0.99      0.95      0.97       912\n",
      "      이륜차주행음       0.94      0.95      0.94       947\n",
      "        차량경적       0.93      0.96      0.94       638\n",
      "       차량사이렌       0.97      0.95      0.96       398\n",
      "       차량주행음       0.86      0.92      0.89       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.94      0.94      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 저장된 모델 로드\n",
    "loaded_model = keras.models.load_model('updated_cnn_model_6classfication.h5')\n",
    "\n",
    "# 모델 구조 확인\n",
    "loaded_model.summary()\n",
    "\n",
    "# 테스트 데이터로 예측 수행\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Loaded Model Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "from sklearn.metrics import classification_report\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29b170-5241-4a2f-9b93-1dac0a62470c",
   "metadata": {},
   "source": [
    "### 차량 주행음 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c22183d-f4f1-4e33-8b88-6f2489b53d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "451/451 [==============================] - 7s 12ms/step - loss: 0.1611 - accuracy: 0.9391 - val_loss: 0.1729 - val_accuracy: 0.9393\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1671 - accuracy: 0.9381 - val_loss: 0.1582 - val_accuracy: 0.9448\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1649 - accuracy: 0.9368 - val_loss: 0.1851 - val_accuracy: 0.9293\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1575 - accuracy: 0.9398 - val_loss: 0.1573 - val_accuracy: 0.9437\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1606 - accuracy: 0.9387 - val_loss: 0.1652 - val_accuracy: 0.9393\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1554 - accuracy: 0.9407 - val_loss: 0.1743 - val_accuracy: 0.9334\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1499 - accuracy: 0.9422 - val_loss: 0.1791 - val_accuracy: 0.9318\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1495 - accuracy: 0.9435 - val_loss: 0.1586 - val_accuracy: 0.9442\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1558 - accuracy: 0.9381 - val_loss: 0.1670 - val_accuracy: 0.9356\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1356 - accuracy: 0.9479 - val_loss: 0.1551 - val_accuracy: 0.9465\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1254 - accuracy: 0.9516 - val_loss: 0.1547 - val_accuracy: 0.9459\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1254 - accuracy: 0.9523 - val_loss: 0.1646 - val_accuracy: 0.9401\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1223 - accuracy: 0.9520 - val_loss: 0.1540 - val_accuracy: 0.9454\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1203 - accuracy: 0.9498 - val_loss: 0.1490 - val_accuracy: 0.9473\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1135 - accuracy: 0.9562 - val_loss: 0.1512 - val_accuracy: 0.9490\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1151 - accuracy: 0.9541 - val_loss: 0.1515 - val_accuracy: 0.9476\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1157 - accuracy: 0.9544 - val_loss: 0.1512 - val_accuracy: 0.9479\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1190 - accuracy: 0.9521 - val_loss: 0.1495 - val_accuracy: 0.9479\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1090 - accuracy: 0.9560 - val_loss: 0.1453 - val_accuracy: 0.9506\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1084 - accuracy: 0.9556 - val_loss: 0.1490 - val_accuracy: 0.9498\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1079 - accuracy: 0.9569 - val_loss: 0.1517 - val_accuracy: 0.9467\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 8ms/step - loss: 0.1129 - accuracy: 0.9554 - val_loss: 0.1555 - val_accuracy: 0.9456\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 6s 13ms/step - loss: 0.1013 - accuracy: 0.9596 - val_loss: 0.1474 - val_accuracy: 0.9512\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.1114 - accuracy: 0.9533 - val_loss: 0.1799 - val_accuracy: 0.9376\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.1088 - accuracy: 0.9568 - val_loss: 0.1524 - val_accuracy: 0.9470\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 7s 16ms/step - loss: 0.1017 - accuracy: 0.9585 - val_loss: 0.1523 - val_accuracy: 0.9492\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.1039 - accuracy: 0.9578 - val_loss: 0.1505 - val_accuracy: 0.9484\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.1041 - accuracy: 0.9571 - val_loss: 0.1482 - val_accuracy: 0.9490\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.1006 - accuracy: 0.9587 - val_loss: 0.1508 - val_accuracy: 0.9487\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 7s 16ms/step - loss: 0.1019 - accuracy: 0.9602 - val_loss: 0.1488 - val_accuracy: 0.9495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "                                                 y=np.argmax(y_train, axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 모델 컴파일 및 학습\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weight_dict, callbacks=[reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af8a72cd-d2c6-43a2-8521-20ab07400cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 9s 16ms/step - loss: 0.7234 - accuracy: 0.7426 - val_loss: 0.3486 - val_accuracy: 0.8741\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 7s 15ms/step - loss: 0.4700 - accuracy: 0.8328 - val_loss: 0.2820 - val_accuracy: 0.8968\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 8s 17ms/step - loss: 0.3877 - accuracy: 0.8623 - val_loss: 0.2684 - val_accuracy: 0.9024\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 7s 16ms/step - loss: 0.3487 - accuracy: 0.8746 - val_loss: 0.2698 - val_accuracy: 0.9021\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 7s 16ms/step - loss: 0.3232 - accuracy: 0.8810 - val_loss: 0.2452 - val_accuracy: 0.9101\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 7s 16ms/step - loss: 0.3095 - accuracy: 0.8880 - val_loss: 0.2746 - val_accuracy: 0.8999\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 8s 17ms/step - loss: 0.2987 - accuracy: 0.8914 - val_loss: 0.2600 - val_accuracy: 0.9049\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2705 - accuracy: 0.9009 - val_loss: 0.2005 - val_accuracy: 0.9270\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2601 - accuracy: 0.9060 - val_loss: 0.1983 - val_accuracy: 0.9276\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2472 - accuracy: 0.9092 - val_loss: 0.2248 - val_accuracy: 0.9209\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2352 - accuracy: 0.9156 - val_loss: 0.1774 - val_accuracy: 0.9340\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2312 - accuracy: 0.9115 - val_loss: 0.1725 - val_accuracy: 0.9381\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2280 - accuracy: 0.9188 - val_loss: 0.1875 - val_accuracy: 0.9318\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2148 - accuracy: 0.9214 - val_loss: 0.2204 - val_accuracy: 0.9173\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2074 - accuracy: 0.9218 - val_loss: 0.2112 - val_accuracy: 0.9229\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2081 - accuracy: 0.9232 - val_loss: 0.1887 - val_accuracy: 0.9340\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1970 - accuracy: 0.9248 - val_loss: 0.1727 - val_accuracy: 0.9373\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1762 - accuracy: 0.9335 - val_loss: 0.1626 - val_accuracy: 0.9393\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1672 - accuracy: 0.9358 - val_loss: 0.1643 - val_accuracy: 0.9404\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1595 - accuracy: 0.9397 - val_loss: 0.1569 - val_accuracy: 0.9415\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1589 - accuracy: 0.9388 - val_loss: 0.1661 - val_accuracy: 0.9395\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1570 - accuracy: 0.9373 - val_loss: 0.1638 - val_accuracy: 0.9395\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1513 - accuracy: 0.9428 - val_loss: 0.1717 - val_accuracy: 0.9368\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1513 - accuracy: 0.9421 - val_loss: 0.1600 - val_accuracy: 0.9415\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1484 - accuracy: 0.9415 - val_loss: 0.1458 - val_accuracy: 0.9492\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1464 - accuracy: 0.9430 - val_loss: 0.1666 - val_accuracy: 0.9398\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1456 - accuracy: 0.9436 - val_loss: 0.1567 - val_accuracy: 0.9429\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1434 - accuracy: 0.9456 - val_loss: 0.1481 - val_accuracy: 0.9465\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1426 - accuracy: 0.9421 - val_loss: 0.1527 - val_accuracy: 0.9445\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1346 - accuracy: 0.9476 - val_loss: 0.1510 - val_accuracy: 0.9451\n",
      "Training model 2/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.7089 - accuracy: 0.7523 - val_loss: 0.4370 - val_accuracy: 0.8258\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4623 - accuracy: 0.8344 - val_loss: 0.2864 - val_accuracy: 0.8999\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3924 - accuracy: 0.8581 - val_loss: 0.2610 - val_accuracy: 0.9074\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3586 - accuracy: 0.8703 - val_loss: 0.2443 - val_accuracy: 0.9049\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.3298 - accuracy: 0.8794 - val_loss: 0.2511 - val_accuracy: 0.9051\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3006 - accuracy: 0.8914 - val_loss: 0.2222 - val_accuracy: 0.9190\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2930 - accuracy: 0.8945 - val_loss: 0.2211 - val_accuracy: 0.9190\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2714 - accuracy: 0.9002 - val_loss: 0.2346 - val_accuracy: 0.9079\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2489 - accuracy: 0.9096 - val_loss: 0.1923 - val_accuracy: 0.9326\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2534 - accuracy: 0.9057 - val_loss: 0.1944 - val_accuracy: 0.9304\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.2402 - accuracy: 0.9123 - val_loss: 0.2010 - val_accuracy: 0.9276\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2370 - accuracy: 0.9126 - val_loss: 0.1825 - val_accuracy: 0.9348\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2247 - accuracy: 0.9154 - val_loss: 0.1930 - val_accuracy: 0.9262\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2148 - accuracy: 0.9196 - val_loss: 0.2110 - val_accuracy: 0.9201\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2082 - accuracy: 0.9216 - val_loss: 0.2008 - val_accuracy: 0.9265\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2072 - accuracy: 0.9225 - val_loss: 0.2007 - val_accuracy: 0.9265\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1946 - accuracy: 0.9272 - val_loss: 0.1721 - val_accuracy: 0.9368\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2010 - accuracy: 0.9274 - val_loss: 0.1546 - val_accuracy: 0.9465\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1902 - accuracy: 0.9282 - val_loss: 0.2337 - val_accuracy: 0.9107\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1787 - accuracy: 0.9304 - val_loss: 0.1946 - val_accuracy: 0.9234\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1822 - accuracy: 0.9295 - val_loss: 0.1940 - val_accuracy: 0.9262\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1772 - accuracy: 0.9333 - val_loss: 0.1576 - val_accuracy: 0.9451\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1649 - accuracy: 0.9369 - val_loss: 0.1773 - val_accuracy: 0.9354\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1556 - accuracy: 0.9406 - val_loss: 0.1632 - val_accuracy: 0.9434\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1466 - accuracy: 0.9437 - val_loss: 0.1660 - val_accuracy: 0.9420\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 10ms/step - loss: 0.1396 - accuracy: 0.9446 - val_loss: 0.1583 - val_accuracy: 0.9467\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.1397 - accuracy: 0.9461 - val_loss: 0.1654 - val_accuracy: 0.9412\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1371 - accuracy: 0.9461 - val_loss: 0.1583 - val_accuracy: 0.9412\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1332 - accuracy: 0.9462 - val_loss: 0.1541 - val_accuracy: 0.9434\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1299 - accuracy: 0.9490 - val_loss: 0.1537 - val_accuracy: 0.9440\n",
      "Training model 3/3\n",
      "Epoch 1/30\n",
      "451/451 [==============================] - 5s 10ms/step - loss: 0.7123 - accuracy: 0.7515 - val_loss: 0.4174 - val_accuracy: 0.8447\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.4618 - accuracy: 0.8355 - val_loss: 0.3108 - val_accuracy: 0.8899\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3908 - accuracy: 0.8611 - val_loss: 0.3486 - val_accuracy: 0.8688\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3426 - accuracy: 0.8790 - val_loss: 0.2594 - val_accuracy: 0.9029\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.3168 - accuracy: 0.8878 - val_loss: 0.2375 - val_accuracy: 0.9112\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2974 - accuracy: 0.8928 - val_loss: 0.2082 - val_accuracy: 0.9265\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2824 - accuracy: 0.9009 - val_loss: 0.2182 - val_accuracy: 0.9209\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2682 - accuracy: 0.9048 - val_loss: 0.2095 - val_accuracy: 0.9229\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2481 - accuracy: 0.9107 - val_loss: 0.1959 - val_accuracy: 0.9237\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2482 - accuracy: 0.9095 - val_loss: 0.2119 - val_accuracy: 0.9193\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2401 - accuracy: 0.9127 - val_loss: 0.1874 - val_accuracy: 0.9295\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2350 - accuracy: 0.9141 - val_loss: 0.2124 - val_accuracy: 0.9207\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2230 - accuracy: 0.9179 - val_loss: 0.1726 - val_accuracy: 0.9395\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2146 - accuracy: 0.9224 - val_loss: 0.1995 - val_accuracy: 0.9251\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2151 - accuracy: 0.9212 - val_loss: 0.1826 - val_accuracy: 0.9320\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.2031 - accuracy: 0.9254 - val_loss: 0.1740 - val_accuracy: 0.9387\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1983 - accuracy: 0.9249 - val_loss: 0.1898 - val_accuracy: 0.9290\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1887 - accuracy: 0.9290 - val_loss: 0.1592 - val_accuracy: 0.9415\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1817 - accuracy: 0.9305 - val_loss: 0.2075 - val_accuracy: 0.9257\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1923 - accuracy: 0.9283 - val_loss: 0.1940 - val_accuracy: 0.9270\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1932 - accuracy: 0.9286 - val_loss: 0.1780 - val_accuracy: 0.9376\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1803 - accuracy: 0.9326 - val_loss: 0.1529 - val_accuracy: 0.9440\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1656 - accuracy: 0.9353 - val_loss: 0.1687 - val_accuracy: 0.9381\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1628 - accuracy: 0.9363 - val_loss: 0.1596 - val_accuracy: 0.9393\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1625 - accuracy: 0.9387 - val_loss: 0.1632 - val_accuracy: 0.9404\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1670 - accuracy: 0.9363 - val_loss: 0.1605 - val_accuracy: 0.9429\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1632 - accuracy: 0.9381 - val_loss: 0.2140 - val_accuracy: 0.9201\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1450 - accuracy: 0.9424 - val_loss: 0.1554 - val_accuracy: 0.9417\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1375 - accuracy: 0.9452 - val_loss: 0.1529 - val_accuracy: 0.9437\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 4s 9ms/step - loss: 0.1364 - accuracy: 0.9465 - val_loss: 0.1506 - val_accuracy: 0.9454\n",
      "Ensemble Accuracy: 0.9467\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.96      0.96      0.96       373\n",
      "       이륜차경적       0.99      0.95      0.97       912\n",
      "      이륜차주행음       0.97      0.91      0.94       947\n",
      "        차량경적       0.93      0.96      0.95       638\n",
      "       차량사이렌       0.99      0.96      0.97       398\n",
      "       차량주행음       0.79      0.96      0.87       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.95      0.94      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[359   1   6   0   3   4]\n",
      " [  0 869   2  41   0   0]\n",
      " [ 11   0 864   0   1  71]\n",
      " [  2   8  10 614   1   3]\n",
      " [  2   0   3   3 382   8]\n",
      " [  1   0  10   1   0 325]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# 데이터 준비 (기존 코드와 동일)\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 classes=np.unique(np.argmax(y_train, axis=1)),\n",
    "                                                 y=np.argmax(y_train, axis=1))\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "# 개선된 CNN 모델 정의\n",
    "def create_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], 1))\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(y_categorical.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "def create_ensemble(num_models=3):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = create_model()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble = create_ensemble()\n",
    "\n",
    "# 학습률 스케줄링\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 모델 학습\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble):\n",
    "    print(f\"Training model {i+1}/{len(ensemble)}\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), \n",
    "                        class_weight=class_weight_dict, callbacks=[reduce_lr])\n",
    "    histories.append(history)\n",
    "\n",
    "# 앙상블 예측\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측\n",
    "y_pred_ensemble = ensemble_predict(ensemble, X_test)\n",
    "y_pred_classes = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9a06bd2-9f57-4e2c-b76d-7fbc2548b825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 updated2_cnn_model_6classfication.h5 파일로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장\n",
    "model.save('updated2_cnn_model_6classfication.h5')\n",
    "print(\"모델이 updated2_cnn_model_6classfication.h5 파일로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceee206-4011-4bca-b270-a367d5011bcb",
   "metadata": {},
   "source": [
    "### 차량주행음 - Precision 과 f1-score 개선\n",
    "- 오버샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31fd3266-6cc3-45ed-a3fb-d159af0e02ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/3\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.6138 - accuracy: 0.7742 - val_loss: 0.3225 - val_accuracy: 0.8832\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.3838 - accuracy: 0.8614 - val_loss: 0.2614 - val_accuracy: 0.9065\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.3116 - accuracy: 0.8887 - val_loss: 0.2307 - val_accuracy: 0.9154\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.2786 - accuracy: 0.8999 - val_loss: 0.2037 - val_accuracy: 0.9257\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.2537 - accuracy: 0.9093 - val_loss: 0.1748 - val_accuracy: 0.9376\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.2321 - accuracy: 0.9179 - val_loss: 0.2162 - val_accuracy: 0.9196\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.2161 - accuracy: 0.9229 - val_loss: 0.2102 - val_accuracy: 0.9215\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.2009 - accuracy: 0.9298 - val_loss: 0.1718 - val_accuracy: 0.9395\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 11s 16ms/step - loss: 0.1933 - accuracy: 0.9311 - val_loss: 0.1997 - val_accuracy: 0.9259\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 13s 18ms/step - loss: 0.1814 - accuracy: 0.9349 - val_loss: 0.1729 - val_accuracy: 0.9368\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 13s 18ms/step - loss: 0.1797 - accuracy: 0.9367 - val_loss: 0.1593 - val_accuracy: 0.9415\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 12s 16ms/step - loss: 0.1693 - accuracy: 0.9391 - val_loss: 0.1505 - val_accuracy: 0.9467\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1642 - accuracy: 0.9422 - val_loss: 0.1820 - val_accuracy: 0.9362\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1583 - accuracy: 0.9424 - val_loss: 0.1654 - val_accuracy: 0.9395\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.1536 - accuracy: 0.9454 - val_loss: 0.1603 - val_accuracy: 0.9417\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1505 - accuracy: 0.9457 - val_loss: 0.1541 - val_accuracy: 0.9423\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.1486 - accuracy: 0.9472 - val_loss: 0.1629 - val_accuracy: 0.9393\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 11s 16ms/step - loss: 0.1299 - accuracy: 0.9544 - val_loss: 0.1489 - val_accuracy: 0.9456\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 12s 17ms/step - loss: 0.1217 - accuracy: 0.9568 - val_loss: 0.1450 - val_accuracy: 0.9445\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.1128 - accuracy: 0.9599 - val_loss: 0.1498 - val_accuracy: 0.9462\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.1138 - accuracy: 0.9597 - val_loss: 0.1514 - val_accuracy: 0.9448\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1082 - accuracy: 0.9600 - val_loss: 0.1483 - val_accuracy: 0.9465\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1134 - accuracy: 0.9595 - val_loss: 0.1540 - val_accuracy: 0.9409\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1077 - accuracy: 0.9621 - val_loss: 0.1405 - val_accuracy: 0.9509\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.1062 - accuracy: 0.9617 - val_loss: 0.1517 - val_accuracy: 0.9459\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1069 - accuracy: 0.9626 - val_loss: 0.1494 - val_accuracy: 0.9470\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1036 - accuracy: 0.9629 - val_loss: 0.1520 - val_accuracy: 0.9448\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.1036 - accuracy: 0.9628 - val_loss: 0.1486 - val_accuracy: 0.9462\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.0993 - accuracy: 0.9630 - val_loss: 0.1485 - val_accuracy: 0.9473\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1000 - accuracy: 0.9632 - val_loss: 0.1433 - val_accuracy: 0.9492\n",
      "Training model 2/3\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 12s 15ms/step - loss: 0.5997 - accuracy: 0.7807 - val_loss: 0.2912 - val_accuracy: 0.8965\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.3654 - accuracy: 0.8677 - val_loss: 0.2843 - val_accuracy: 0.8946\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.3067 - accuracy: 0.8890 - val_loss: 0.2531 - val_accuracy: 0.9004\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.2803 - accuracy: 0.9012 - val_loss: 0.2006 - val_accuracy: 0.9262\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 9s 13ms/step - loss: 0.2548 - accuracy: 0.9100 - val_loss: 0.1968 - val_accuracy: 0.9287\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.2210 - accuracy: 0.9219 - val_loss: 0.1799 - val_accuracy: 0.9356\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.2183 - accuracy: 0.9231 - val_loss: 0.1837 - val_accuracy: 0.9348\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 7s 9ms/step - loss: 0.2056 - accuracy: 0.9269 - val_loss: 0.2125 - val_accuracy: 0.9196\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1932 - accuracy: 0.9324 - val_loss: 0.1808 - val_accuracy: 0.9343\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1838 - accuracy: 0.9346 - val_loss: 0.1740 - val_accuracy: 0.9404\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1732 - accuracy: 0.9388 - val_loss: 0.1566 - val_accuracy: 0.9409\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1667 - accuracy: 0.9412 - val_loss: 0.1640 - val_accuracy: 0.9429\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1677 - accuracy: 0.9399 - val_loss: 0.1560 - val_accuracy: 0.9417\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1551 - accuracy: 0.9457 - val_loss: 0.1600 - val_accuracy: 0.9426\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1504 - accuracy: 0.9458 - val_loss: 0.1527 - val_accuracy: 0.9467\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1486 - accuracy: 0.9468 - val_loss: 0.1716 - val_accuracy: 0.9395\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1486 - accuracy: 0.9471 - val_loss: 0.1857 - val_accuracy: 0.9348\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1393 - accuracy: 0.9509 - val_loss: 0.1487 - val_accuracy: 0.9467\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1388 - accuracy: 0.9510 - val_loss: 0.1576 - val_accuracy: 0.9440\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1358 - accuracy: 0.9518 - val_loss: 0.1738 - val_accuracy: 0.9390\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1297 - accuracy: 0.9527 - val_loss: 0.1561 - val_accuracy: 0.9451\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 6s 9ms/step - loss: 0.1303 - accuracy: 0.9531 - val_loss: 0.1739 - val_accuracy: 0.9395\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 7s 10ms/step - loss: 0.1272 - accuracy: 0.9556 - val_loss: 0.1474 - val_accuracy: 0.9492\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1197 - accuracy: 0.9563 - val_loss: 0.1732 - val_accuracy: 0.9417\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.1253 - accuracy: 0.9540 - val_loss: 0.1510 - val_accuracy: 0.9473\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1165 - accuracy: 0.9592 - val_loss: 0.1740 - val_accuracy: 0.9373\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1162 - accuracy: 0.9589 - val_loss: 0.1588 - val_accuracy: 0.9476\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1192 - accuracy: 0.9567 - val_loss: 0.1660 - val_accuracy: 0.9417\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1039 - accuracy: 0.9643 - val_loss: 0.1557 - val_accuracy: 0.9409\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 9s 13ms/step - loss: 0.0930 - accuracy: 0.9650 - val_loss: 0.1425 - val_accuracy: 0.9503\n",
      "Training model 3/3\n",
      "Epoch 1/30\n",
      "711/711 [==============================] - 11s 14ms/step - loss: 0.5912 - accuracy: 0.7848 - val_loss: 0.3316 - val_accuracy: 0.8788\n",
      "Epoch 2/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.3721 - accuracy: 0.8667 - val_loss: 0.2481 - val_accuracy: 0.9074\n",
      "Epoch 3/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.3059 - accuracy: 0.8902 - val_loss: 0.2187 - val_accuracy: 0.9196\n",
      "Epoch 4/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.2681 - accuracy: 0.9045 - val_loss: 0.2239 - val_accuracy: 0.9215\n",
      "Epoch 5/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.2410 - accuracy: 0.9137 - val_loss: 0.2240 - val_accuracy: 0.9212\n",
      "Epoch 6/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.2247 - accuracy: 0.9201 - val_loss: 0.1934 - val_accuracy: 0.9312\n",
      "Epoch 7/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.2123 - accuracy: 0.9255 - val_loss: 0.1798 - val_accuracy: 0.9365\n",
      "Epoch 8/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.2032 - accuracy: 0.9251 - val_loss: 0.2294 - val_accuracy: 0.9160\n",
      "Epoch 9/30\n",
      "711/711 [==============================] - 11s 16ms/step - loss: 0.1918 - accuracy: 0.9318 - val_loss: 0.1957 - val_accuracy: 0.9315\n",
      "Epoch 10/30\n",
      "711/711 [==============================] - 10s 15ms/step - loss: 0.1777 - accuracy: 0.9374 - val_loss: 0.1854 - val_accuracy: 0.9320\n",
      "Epoch 11/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.1702 - accuracy: 0.9410 - val_loss: 0.1647 - val_accuracy: 0.9406\n",
      "Epoch 12/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1592 - accuracy: 0.9430 - val_loss: 0.1828 - val_accuracy: 0.9337\n",
      "Epoch 13/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1576 - accuracy: 0.9445 - val_loss: 0.1720 - val_accuracy: 0.9393\n",
      "Epoch 14/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1487 - accuracy: 0.9462 - val_loss: 0.1796 - val_accuracy: 0.9340\n",
      "Epoch 15/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1549 - accuracy: 0.9474 - val_loss: 0.1645 - val_accuracy: 0.9437\n",
      "Epoch 16/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1512 - accuracy: 0.9461 - val_loss: 0.1921 - val_accuracy: 0.9301\n",
      "Epoch 17/30\n",
      "711/711 [==============================] - 11s 15ms/step - loss: 0.1448 - accuracy: 0.9479 - val_loss: 0.1639 - val_accuracy: 0.9398\n",
      "Epoch 18/30\n",
      "711/711 [==============================] - 10s 14ms/step - loss: 0.1363 - accuracy: 0.9503 - val_loss: 0.1771 - val_accuracy: 0.9381\n",
      "Epoch 19/30\n",
      "711/711 [==============================] - 7s 10ms/step - loss: 0.1307 - accuracy: 0.9527 - val_loss: 0.1603 - val_accuracy: 0.9484\n",
      "Epoch 20/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1370 - accuracy: 0.9507 - val_loss: 0.1714 - val_accuracy: 0.9404\n",
      "Epoch 21/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1287 - accuracy: 0.9527 - val_loss: 0.1738 - val_accuracy: 0.9404\n",
      "Epoch 22/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1230 - accuracy: 0.9562 - val_loss: 0.1661 - val_accuracy: 0.9462\n",
      "Epoch 23/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1195 - accuracy: 0.9573 - val_loss: 0.1566 - val_accuracy: 0.9442\n",
      "Epoch 24/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1257 - accuracy: 0.9561 - val_loss: 0.1623 - val_accuracy: 0.9406\n",
      "Epoch 25/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1188 - accuracy: 0.9585 - val_loss: 0.1455 - val_accuracy: 0.9479\n",
      "Epoch 26/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1197 - accuracy: 0.9580 - val_loss: 0.1542 - val_accuracy: 0.9498\n",
      "Epoch 27/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1192 - accuracy: 0.9569 - val_loss: 0.1798 - val_accuracy: 0.9393\n",
      "Epoch 28/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1089 - accuracy: 0.9632 - val_loss: 0.1608 - val_accuracy: 0.9434\n",
      "Epoch 29/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1090 - accuracy: 0.9589 - val_loss: 0.1527 - val_accuracy: 0.9495\n",
      "Epoch 30/30\n",
      "711/711 [==============================] - 6s 8ms/step - loss: 0.1091 - accuracy: 0.9605 - val_loss: 0.1973 - val_accuracy: 0.9323\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Dropout, Flatten, Input, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "# 레이블 인코딩 및 데이터 분할\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 오버샘플링 적용 (훈련 데이터만)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# 원-핫 인코딩\n",
    "y_train_categorical = to_categorical(y_train_resampled)\n",
    "y_test_categorical = to_categorical(y_test)\n",
    "\n",
    "# 데이터 형태 변환\n",
    "X_train_resampled = X_train_resampled.reshape(X_train_resampled.shape[0], X_train_resampled.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# CNN 모델 정의\n",
    "def create_model():\n",
    "    inputs = Input(shape=(X_train_resampled.shape[1], 1))\n",
    "    x = Conv1D(64, kernel_size=3, activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, kernel_size=3, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size=2)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(y_test_categorical.shape[1], activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "# 앙상블 모델 생성\n",
    "def create_ensemble(num_models=3):\n",
    "    models = []\n",
    "    for _ in range(num_models):\n",
    "        model = create_model()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# 앙상블 모델 학습\n",
    "ensemble = create_ensemble()\n",
    "\n",
    "# 학습률 스케줄링 콜백 정의\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.0001)\n",
    "\n",
    "# 모델 학습 (오버샘플링된 데이터 사용)\n",
    "histories = []\n",
    "for i, model in enumerate(ensemble):\n",
    "    print(f\"Training model {i+1}/{len(ensemble)}\")\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train_resampled, y_train_categorical,\n",
    "                        epochs=30,\n",
    "                        batch_size=32,\n",
    "                        validation_data=(X_test, y_test_categorical),\n",
    "                        callbacks=[reduce_lr])\n",
    "    histories.append(history)\n",
    "\n",
    "# 앙상블 예측 함수 정의\n",
    "def ensemble_predict(models, X):\n",
    "    predictions = [model.predict(X) for model in models]\n",
    "    return np.mean(predictions, axis=0)\n",
    "\n",
    "# 테스트 데이터에 대한 앙상블 예측 수행\n",
    "y_pred_ensemble = ensemble_predict(ensemble, X_test)\n",
    "\n",
    "# 클래스별로 가장 높은 확률을 가진\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f94fb2a0-4699-48f7-abe5-a6ab28b03f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9481\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.96      0.97      0.97       373\n",
      "       이륜차경적       0.98      0.95      0.97       912\n",
      "      이륜차주행음       0.96      0.92      0.94       947\n",
      "        차량경적       0.94      0.96      0.95       638\n",
      "       차량사이렌       0.98      0.96      0.97       398\n",
      "       차량주행음       0.81      0.96      0.88       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[362   1   6   0   2   2]\n",
      " [  0 869   2  41   0   0]\n",
      " [ 11   0 871   0   2  63]\n",
      " [  0  14  10 610   1   3]\n",
      " [  2   0   3   1 383   9]\n",
      " [  1   0  11   0   2 323]]\n"
     ]
    }
   ],
   "source": [
    "# 클래스별로 가장 높은 확률을 가진 클래스 인덱스를 선택\n",
    "y_pred_classes = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_true_classes = np.argmax(y_test_categorical, axis=1)\n",
    "\n",
    "# 정확도 계산 및 출력\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Ensemble Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449aec16-cea2-4e4e-ba11-6a89faef0790",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "badb38b0-39a1-497e-9cad-1032c4faad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LightGBM 정확도: 0.9451\n",
      "\n",
      "🎯 Confusion Matrix:\n",
      "   기타소음  이륜차경적  이륜차주행음  차량경적  차량사이렌  차량주행음\n",
      "0   346      4      15     1      4      3\n",
      "1     3    870       2    37      0      0\n",
      "2    15      1     912     1      0     18\n",
      "3     1     22      14   595      1      5\n",
      "4     2      0       4     1    385      6\n",
      "5     6      0      31     1      0    299\n",
      "\n",
      "📊 Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.93      0.93      0.93       373\n",
      "       이륜차경적       0.97      0.95      0.96       912\n",
      "      이륜차주행음       0.93      0.96      0.95       947\n",
      "        차량경적       0.94      0.93      0.93       638\n",
      "       차량사이렌       0.99      0.97      0.98       398\n",
      "       차량주행음       0.90      0.89      0.90       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.94      0.94      0.94      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "# 소음 카테고리 변환 함수\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values  # MFCC 특징 값\n",
    "y = df['label'].values       # 레이블\n",
    "\n",
    "# 레이블 인코딩 (문자 → 숫자)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# 데이터셋 분할 (훈련:테스트 = 80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "# LightGBM 모델 정의 및 학습\n",
    "model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_test, y_pred, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "\n",
    "\n",
    "# # 📌 5. LGBM 모델 정의 및 학습\n",
    "# model = LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=-1, random_state=42)\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # 📌 6. 예측 수행\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "# # 📌 7. 평가 결과 출력\n",
    "# acc = accuracy_score(y_test, y_pred)\n",
    "# print(f\"✅ LightGBM 정확도: {acc:.4f}\")\n",
    "\n",
    "# # 📌 8. 혼동 행렬 출력\n",
    "# print(\"\\n🎯 Confusion Matrix:\")\n",
    "# conf_matrix = pd.DataFrame(confusion_matrix(y_test, y_pred), columns=class_names)\n",
    "# print(conf_matrix)\n",
    "\n",
    "# # 📌 9. 분류 보고서 출력\n",
    "# print(\"\\n📊 Classification Report:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=class_names.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e43b1d-0e0d-4494-9453-5512e8262b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c62be1d6-915c-4713-bf59-da177619efd7",
   "metadata": {},
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11fe2a30-0a4a-4d27-91c2-8fd030e2e00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "451/451 [==============================] - 17s 31ms/step - loss: 0.4224 - accuracy: 0.8466 - val_loss: 0.4001 - val_accuracy: 0.8749\n",
      "Epoch 2/30\n",
      "451/451 [==============================] - 14s 30ms/step - loss: 0.2593 - accuracy: 0.9084 - val_loss: 0.2376 - val_accuracy: 0.9204\n",
      "Epoch 3/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.1922 - accuracy: 0.9308 - val_loss: 0.1670 - val_accuracy: 0.9387\n",
      "Epoch 4/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.1707 - accuracy: 0.9372 - val_loss: 0.2102 - val_accuracy: 0.9243\n",
      "Epoch 5/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.1465 - accuracy: 0.9467 - val_loss: 0.2328 - val_accuracy: 0.9209\n",
      "Epoch 6/30\n",
      "451/451 [==============================] - 19s 42ms/step - loss: 0.1316 - accuracy: 0.9521 - val_loss: 0.2120 - val_accuracy: 0.9345\n",
      "Epoch 7/30\n",
      "451/451 [==============================] - 21s 46ms/step - loss: 0.1309 - accuracy: 0.9502 - val_loss: 0.1763 - val_accuracy: 0.9373\n",
      "Epoch 8/30\n",
      "451/451 [==============================] - 23s 51ms/step - loss: 0.1076 - accuracy: 0.9587 - val_loss: 0.1661 - val_accuracy: 0.9442\n",
      "Epoch 9/30\n",
      "451/451 [==============================] - 24s 54ms/step - loss: 0.1111 - accuracy: 0.9577 - val_loss: 0.1977 - val_accuracy: 0.9334\n",
      "Epoch 10/30\n",
      "451/451 [==============================] - 25s 55ms/step - loss: 0.0930 - accuracy: 0.9645 - val_loss: 0.1632 - val_accuracy: 0.9459\n",
      "Epoch 11/30\n",
      "451/451 [==============================] - 25s 55ms/step - loss: 0.0872 - accuracy: 0.9656 - val_loss: 0.2032 - val_accuracy: 0.9359\n",
      "Epoch 12/30\n",
      "451/451 [==============================] - 24s 54ms/step - loss: 0.0814 - accuracy: 0.9680 - val_loss: 0.1932 - val_accuracy: 0.9434\n",
      "Epoch 13/30\n",
      "451/451 [==============================] - 23s 51ms/step - loss: 0.0746 - accuracy: 0.9711 - val_loss: 0.1979 - val_accuracy: 0.9368\n",
      "Epoch 14/30\n",
      "451/451 [==============================] - 17s 38ms/step - loss: 0.0772 - accuracy: 0.9703 - val_loss: 0.1848 - val_accuracy: 0.9462\n",
      "Epoch 15/30\n",
      "451/451 [==============================] - 14s 32ms/step - loss: 0.0724 - accuracy: 0.9715 - val_loss: 0.1793 - val_accuracy: 0.9412\n",
      "Epoch 16/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0572 - accuracy: 0.9782 - val_loss: 0.1894 - val_accuracy: 0.9448\n",
      "Epoch 17/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0555 - accuracy: 0.9772 - val_loss: 0.1976 - val_accuracy: 0.9387\n",
      "Epoch 18/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0603 - accuracy: 0.9763 - val_loss: 0.1761 - val_accuracy: 0.9440\n",
      "Epoch 19/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0566 - accuracy: 0.9778 - val_loss: 0.2768 - val_accuracy: 0.9215\n",
      "Epoch 20/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0503 - accuracy: 0.9795 - val_loss: 0.1497 - val_accuracy: 0.9515\n",
      "Epoch 21/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0538 - accuracy: 0.9788 - val_loss: 0.1958 - val_accuracy: 0.9423\n",
      "Epoch 22/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0415 - accuracy: 0.9828 - val_loss: 0.1806 - val_accuracy: 0.9456\n",
      "Epoch 23/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0411 - accuracy: 0.9829 - val_loss: 0.1921 - val_accuracy: 0.9501\n",
      "Epoch 24/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0450 - accuracy: 0.9820 - val_loss: 0.1640 - val_accuracy: 0.9490\n",
      "Epoch 25/30\n",
      "451/451 [==============================] - 14s 31ms/step - loss: 0.0371 - accuracy: 0.9850 - val_loss: 0.1871 - val_accuracy: 0.9487\n",
      "Epoch 26/30\n",
      "451/451 [==============================] - 19s 43ms/step - loss: 0.0339 - accuracy: 0.9861 - val_loss: 0.2008 - val_accuracy: 0.9470\n",
      "Epoch 27/30\n",
      "451/451 [==============================] - 21s 47ms/step - loss: 0.0475 - accuracy: 0.9822 - val_loss: 0.2236 - val_accuracy: 0.9423\n",
      "Epoch 28/30\n",
      "451/451 [==============================] - 27s 60ms/step - loss: 0.0383 - accuracy: 0.9837 - val_loss: 0.1660 - val_accuracy: 0.9473\n",
      "Epoch 29/30\n",
      "451/451 [==============================] - 25s 55ms/step - loss: 0.0343 - accuracy: 0.9847 - val_loss: 0.2496 - val_accuracy: 0.9359\n",
      "Epoch 30/30\n",
      "451/451 [==============================] - 25s 56ms/step - loss: 0.0369 - accuracy: 0.9853 - val_loss: 0.1784 - val_accuracy: 0.9487\n",
      "Accuracy: 0.9487\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        기타소음       0.96      0.97      0.96       373\n",
      "       이륜차경적       0.96      0.96      0.96       912\n",
      "      이륜차주행음       0.95      0.95      0.95       947\n",
      "        차량경적       0.94      0.93      0.93       638\n",
      "       차량사이렌       0.97      0.97      0.97       398\n",
      "       차량주행음       0.90      0.91      0.90       337\n",
      "\n",
      "    accuracy                           0.95      3605\n",
      "   macro avg       0.95      0.95      0.95      3605\n",
      "weighted avg       0.95      0.95      0.95      3605\n",
      "\n",
      "Confusion Matrix:\n",
      " [[361   1   7   1   1   2]\n",
      " [  0 873   3  35   1   0]\n",
      " [ 11   0 904   1   5  26]\n",
      " [  1  31  11 591   2   2]\n",
      " [  3   0   3   3 386   3]\n",
      " [  0   0  27   1   4 305]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Activation, Add, GlobalAveragePooling1D, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# 데이터 준비\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "# 소음 카테고리 변환 함수\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "X = df[feature_cols].values  # MFCC 특징 값\n",
    "y = df['label'].values       # 레이블\n",
    "\n",
    "# 레이블 인코딩 (문자 → 숫자)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_categorical = to_categorical(y_encoded)  # One-hot 인코딩\n",
    "\n",
    "# 데이터셋 분할 (훈련:테스트 = 80:20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_categorical, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# CNN 입력 형태로 변환 (3D 텐서: 샘플 수 x 시간 축 x 특징 수)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "# ResNet 블록 정의\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, strides=stride, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# ResNet 모델 정의\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, 7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    x = residual_block(x, 128)\n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = residual_block(x, 256)\n",
    "    \n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# 모델 생성 및 컴파일\n",
    "model = build_resnet(input_shape=(X_train.shape[1], 1), num_classes=y_categorical.shape[1])\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# 테스트 데이터에 대한 예측 수행\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # 예측된 클래스 인덱스\n",
    "y_true_classes = np.argmax(y_test, axis=1)  # 실제 클래스 인덱스\n",
    "\n",
    "# 정확도 계산\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# 분류 보고서 출력\n",
    "class_names = label_encoder.classes_\n",
    "report = classification_report(y_true_classes, y_pred_classes, target_names=class_names)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "# 혼동 행렬 출력\n",
    "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e1796-51e6-4d3d-a92f-25b77312c11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd9d4ae9-1427-4bfe-b054-04420055ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1352/1352 [==============================] - 93s 67ms/step - loss: 0.5031 - accuracy: 0.8219 - val_loss: 0.2931 - val_accuracy: 0.9043\n",
      "Epoch 2/30\n",
      "1352/1352 [==============================] - 88s 65ms/step - loss: 0.2956 - accuracy: 0.8900 - val_loss: 0.2821 - val_accuracy: 0.9004\n",
      "Epoch 3/30\n",
      "1352/1352 [==============================] - 87s 64ms/step - loss: 0.2332 - accuracy: 0.9119 - val_loss: 0.1842 - val_accuracy: 0.9312\n",
      "Epoch 4/30\n",
      "1352/1352 [==============================] - 82s 61ms/step - loss: 0.1939 - accuracy: 0.9253 - val_loss: 0.2205 - val_accuracy: 0.9234\n",
      "Epoch 5/30\n",
      "1352/1352 [==============================] - 81s 60ms/step - loss: 0.1646 - accuracy: 0.9359 - val_loss: 0.2177 - val_accuracy: 0.9221\n",
      "Epoch 6/30\n",
      "1352/1352 [==============================] - 81s 60ms/step - loss: 0.1413 - accuracy: 0.9435 - val_loss: 0.2011 - val_accuracy: 0.9334\n",
      "Epoch 7/30\n",
      "1352/1352 [==============================] - 84s 62ms/step - loss: 0.1164 - accuracy: 0.9520 - val_loss: 0.1944 - val_accuracy: 0.9376\n",
      "Epoch 8/30\n",
      "1352/1352 [==============================] - 88s 65ms/step - loss: 0.1056 - accuracy: 0.9562 - val_loss: 0.1720 - val_accuracy: 0.9431\n",
      "Epoch 9/30\n",
      "1352/1352 [==============================] - 84s 62ms/step - loss: 0.0902 - accuracy: 0.9612 - val_loss: 0.1898 - val_accuracy: 0.9406\n",
      "Epoch 10/30\n",
      "1352/1352 [==============================] - 88s 65ms/step - loss: 0.0864 - accuracy: 0.9639 - val_loss: 0.1880 - val_accuracy: 0.9503\n",
      "Epoch 11/30\n",
      "1352/1352 [==============================] - 83s 61ms/step - loss: 0.0691 - accuracy: 0.9713 - val_loss: 0.2199 - val_accuracy: 0.9387\n",
      "Epoch 12/30\n",
      "1352/1352 [==============================] - 88s 65ms/step - loss: 0.0705 - accuracy: 0.9716 - val_loss: 0.2038 - val_accuracy: 0.9417\n",
      "Epoch 13/30\n",
      "1352/1352 [==============================] - 91s 67ms/step - loss: 0.0582 - accuracy: 0.9748 - val_loss: 0.2282 - val_accuracy: 0.9412\n",
      "Epoch 14/30\n",
      "1352/1352 [==============================] - 92s 68ms/step - loss: 0.0542 - accuracy: 0.9777 - val_loss: 0.2301 - val_accuracy: 0.9398\n",
      "Epoch 15/30\n",
      "1352/1352 [==============================] - 95s 70ms/step - loss: 0.0541 - accuracy: 0.9764 - val_loss: 0.1944 - val_accuracy: 0.9476\n",
      "Epoch 16/30\n",
      "1352/1352 [==============================] - 92s 68ms/step - loss: 0.0472 - accuracy: 0.9797 - val_loss: 0.2565 - val_accuracy: 0.9379\n",
      "Epoch 17/30\n",
      "1352/1352 [==============================] - 88s 65ms/step - loss: 0.0479 - accuracy: 0.9796 - val_loss: 0.2250 - val_accuracy: 0.9459\n",
      "Epoch 18/30\n",
      "1352/1352 [==============================] - 89s 66ms/step - loss: 0.0432 - accuracy: 0.9819 - val_loss: 0.2349 - val_accuracy: 0.9473\n",
      "Epoch 19/30\n",
      "1352/1352 [==============================] - 91s 67ms/step - loss: 0.0204 - accuracy: 0.9900 - val_loss: 0.2248 - val_accuracy: 0.9501\n",
      "Epoch 20/30\n",
      "1352/1352 [==============================] - 92s 68ms/step - loss: 0.0152 - accuracy: 0.9924 - val_loss: 0.2571 - val_accuracy: 0.9462\n",
      "Epoch 21/30\n",
      "1352/1352 [==============================] - 90s 66ms/step - loss: 0.0164 - accuracy: 0.9920 - val_loss: 0.2485 - val_accuracy: 0.9537\n",
      "Epoch 22/30\n",
      "1352/1352 [==============================] - 92s 68ms/step - loss: 0.0126 - accuracy: 0.9934 - val_loss: 0.2823 - val_accuracy: 0.9459\n",
      "Epoch 23/30\n",
      "1352/1352 [==============================] - 91s 67ms/step - loss: 0.0177 - accuracy: 0.9917 - val_loss: 0.2960 - val_accuracy: 0.9462\n",
      "Epoch 24/30\n",
      "1352/1352 [==============================] - 91s 67ms/step - loss: 0.0130 - accuracy: 0.9933 - val_loss: 0.3128 - val_accuracy: 0.9426\n",
      "Epoch 25/30\n",
      "1352/1352 [==============================] - 92s 68ms/step - loss: 0.0127 - accuracy: 0.9930 - val_loss: 0.2829 - val_accuracy: 0.9490\n",
      "Epoch 26/30\n",
      "1352/1352 [==============================] - 91s 67ms/step - loss: 0.0150 - accuracy: 0.9924 - val_loss: 0.3819 - val_accuracy: 0.9307\n",
      "Epoch 27/30\n",
      "1352/1352 [==============================] - 90s 67ms/step - loss: 0.0126 - accuracy: 0.9932 - val_loss: 0.2880 - val_accuracy: 0.9456\n",
      "Epoch 28/30\n",
      "1352/1352 [==============================] - 91s 67ms/step - loss: 0.0137 - accuracy: 0.9931 - val_loss: 0.2997 - val_accuracy: 0.9503\n",
      "113/113 [==============================] - 1s 7ms/step - loss: 0.1720 - accuracy: 0.9431\n",
      "Test accuracy: 0.9431\n",
      "Accuracy for class '기타소음': 0.9875\n",
      "Accuracy for class '이륜차경적': 0.9817\n",
      "Accuracy for class '이륜차주행음': 0.9687\n",
      "Accuracy for class '차량경적': 0.9770\n",
      "Accuracy for class '차량사이렌': 0.9914\n",
      "Accuracy for class '차량주행음': 0.9800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalAveragePooling1D, Dense, BatchNormalization, Add, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 데이터 준비\n",
    "df = pd.read_csv(\"combined_result.csv\", encoding='utf-8')\n",
    "feature_cols = [f'mfcc_{i}' for i in range(1, 51)]\n",
    "df = df[feature_cols + ['category_03']]\n",
    "\n",
    "# 소음 카테고리 변환 함수\n",
    "def categorize_noise(category):\n",
    "    if category in ['이륜차경적']:\n",
    "        return '이륜차경적'\n",
    "    elif category in ['이륜차주행음']:\n",
    "        return '이륜차주행음'\n",
    "    elif category in ['차량사이렌']:\n",
    "        return '차량사이렌'\n",
    "    elif category in ['차량주행음']:\n",
    "        return '차량주행음'\n",
    "    elif category in ['차량경적']:\n",
    "        return '차량경적'\n",
    "    else:\n",
    "        return '기타소음'\n",
    "\n",
    "df['label'] = df['category_03'].apply(categorize_noise)\n",
    "df = df.drop('category_03', axis=1)\n",
    "\n",
    "# 특성과 레이블 분리\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "# 레이블 인코딩\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 데이터 증강 함수\n",
    "def augment_data(X, y):\n",
    "    X_augmented = []\n",
    "    y_augmented = []\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        X_augmented.append(X[i])\n",
    "        y_augmented.append(y[i])\n",
    "        \n",
    "        # 노이즈 추가\n",
    "        noise = np.random.normal(0, 0.01, X[i].shape)\n",
    "        X_augmented.append(X[i] + noise)\n",
    "        y_augmented.append(y[i])\n",
    "        \n",
    "        # 시간 축 이동\n",
    "        shift = np.random.randint(-5, 6)\n",
    "        X_augmented.append(np.roll(X[i], shift))\n",
    "        y_augmented.append(y[i])\n",
    "    \n",
    "    return np.array(X_augmented), np.array(y_augmented)\n",
    "\n",
    "# 데이터 증강 적용\n",
    "X_train_augmented, y_train_augmented = augment_data(X_train, y_train)\n",
    "\n",
    "# 데이터 형태 변환 (ResNet 입력 형태)\n",
    "X_train_augmented = X_train_augmented.reshape((X_train_augmented.shape[0], X_train_augmented.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# One-hot encoding\n",
    "num_classes = len(np.unique(y))\n",
    "y_train_augmented = to_categorical(y_train_augmented, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# ResNet 모델 구축\n",
    "def residual_block(x, filters, kernel_size=3, stride=1):\n",
    "    shortcut = x\n",
    "    x = Conv1D(filters, kernel_size, strides=stride, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv1D(filters, kernel_size, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, strides=stride, padding='same')(shortcut)\n",
    "    x = Add()([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv1D(64, 7, strides=2, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = residual_block(x, 512, stride=2)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dense(num_classes, activation='softmax')(x)\n",
    "    return Model(inputs, x)\n",
    "\n",
    "# 모델 생성 및 컴파일\n",
    "resnet_model = build_resnet(X_train_augmented.shape[1:], num_classes=num_classes)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "resnet_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.00001)\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "unique_classes = np.unique(y_train)\n",
    "class_weights = class_weight.compute_class_weight('balanced', \n",
    "                                                  classes=unique_classes, \n",
    "                                                  y=y_train)\n",
    "class_weights_dict = dict(zip(unique_classes, class_weights))\n",
    "\n",
    "history = resnet_model.fit(X_train_augmented, y_train_augmented, epochs=30, batch_size=32, \n",
    "                           validation_data=(X_test, y_test), callbacks=[early_stopping, reduce_lr], \n",
    "                           class_weight=class_weights_dict)\n",
    "\n",
    "# 모델 평가\n",
    "test_loss, test_accuracy = resnet_model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# 클래스별 정확도 출력\n",
    "y_pred = resnet_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    class_accuracy = np.mean((y_pred_classes == i) == (y_true_classes == i))\n",
    "    print(f\"Accuracy for class '{class_name}': {class_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d071eb4-2313-4fc6-8ea6-b9f9174a9ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae53cb5a-27fd-49fe-a4b1-9c12873abd6f",
   "metadata": {},
   "source": [
    "# 새로운 wav 파일 분류 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e9a30c0-5e9a-4f24-82f8-fbc631a4d578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_audio(audio_path):\n",
    "    try:\n",
    "        # 음원 파일 로드\n",
    "        y, sr = librosa.load(audio_path, sr=44100)\n",
    "\n",
    "        # MFCC 특징 추출\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=50)\n",
    "\n",
    "        # 추출된 MFCC 특징의 평균값을 사용 (각 MFCC 차수별로 하나의 값)\n",
    "        mfccs_processed = np.mean(mfccs, axis=1)\n",
    "\n",
    "        # CNN 입력 형태로 변환 (3D 텐서)\n",
    "        new_data = mfccs_processed.reshape(1, -1, 1)\n",
    "\n",
    "        # 예측 수행\n",
    "        predicted_label_encoded = np.argmax(model.predict(new_data), axis=-1)[0]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "\n",
    "        return predicted_label\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio file: {e}\")\n",
    "        return \"Unknown\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c698d007-e120-4a7f-8e58-b9f5c42014f5",
   "metadata": {},
   "source": [
    "## 기타소음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f180ef-d9a5-4f60-96ae-2ba57292bd9e",
   "metadata": {},
   "source": [
    "### 고양이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5f6d5a4-8249-4813-be6b-510b1e614ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 274/274 [00:33<00:00,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'cat.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_04/동물/15.고양이\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_cat = pd.DataFrame(results)\n",
    "results_df_cat.to_csv(\"cat.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'cat.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb3b05ae-f805-4b56-a9f2-dba96b86e90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      269\n",
       "차량사이렌       4\n",
       "이륜차주행음      1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_cat['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f664effd-8c60-493c-ba28-623e11740e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 274\n",
      "'기타소음' Count: 269\n",
      "'기타소음' Ratio: 98.18%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_cat)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_cat[results_df_cat['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ca8ad8",
   "metadata": {},
   "source": [
    "### 항공기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92ebccdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 191/191 [00:59<00:00,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'airplane.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_04/교통소음/3.항공기/6.비행기\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_airplane = pd.DataFrame(results)\n",
    "results_df_airplane.to_csv(\"airplane.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'airplane.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8851b253-db48-47ef-ad1a-6cecebb59f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      172\n",
       "이륜차주행음     11\n",
       "차량주행음       7\n",
       "차량사이렌       1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_airplane['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "764059f8-07fc-4862-adc4-df50e8ea1e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 191\n",
      "'기타소음' Count: 172\n",
      "'기타소음' Ratio: 90.05%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_airplane)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_airplane[results_df_airplane['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1033c4f5-a370-4e3d-afb9-90a573e8b1f6",
   "metadata": {},
   "source": [
    "### 헬리콥터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12bb0e5d-4b87-4855-a0c3-35d758d921f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 435/435 [00:53<00:00,  8.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'helicopter.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_04/교통소음/3.항공기/7.헬리콥터\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_helicopter = pd.DataFrame(results)\n",
    "results_df_helicopter.to_csv(\"helicopter.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'helicopter.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83a81ea4-a36d-4b88-a863-123842798674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음     434\n",
       "차량사이렌      1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_helicopter['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57c04930-61f1-4a0c-9a0c-8ae67136038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 435\n",
      "'기타소음' Count: 434\n",
      "'기타소음' Ratio: 99.77%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_helicopter)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_helicopter[results_df_helicopter['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cee9b5-d114-451d-b0fe-cb1657da67ab",
   "metadata": {},
   "source": [
    "### 가전 청소기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3eea1d3-8a69-41d2-8a38-88e0ceecfbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [00:48<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'vacuum.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/etc_noise_data_test_04/가전/12.청소기\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_vacuum = pd.DataFrame(results)\n",
    "results_df_vacuum.to_csv(\"vacuum.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'vacuum.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "866304c4-3d5b-4b54-a3aa-4e03c54401b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기타소음      97\n",
       "이륜차주행음     2\n",
       "차량경적       2\n",
       "이륜차경적      1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_vacuum['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b5f548c-099a-46c4-b9ad-be302b7595ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 102\n",
      "'기타소음' Count: 97\n",
      "'기타소음' Ratio: 95.10%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_vacuum)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_vacuum[results_df_vacuum['Predicted Label'] == '기타소음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'기타소음' Count: {etc_noise_count}\")\n",
    "print(f\"'기타소음' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b417044",
   "metadata": {},
   "source": [
    "## 교통소음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0cab28-a711-48c7-8881-0653e74cd689",
   "metadata": {},
   "source": [
    "### 차량 사이렌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a08555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 249/249 [00:31<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'car_siren.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/test_data/raw_data_test/1.Car/2.siren_of_car\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_car_siren = pd.DataFrame(results)\n",
    "results_df_car_siren.to_csv(\"car_siren.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'car_siren.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e4248b0-fd4d-4806-8ef9-2ed3e5b9ae08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량사이렌     240\n",
       "차량주행음       4\n",
       "이륜차주행음      3\n",
       "기타소음        1\n",
       "이륜차경적       1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_car_siren['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f9027dd-bc1e-4a62-b58e-a189d8875336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 249\n",
      "'차량사이렌' Count: 240\n",
      "'차량사이렌' Ratio: 96.39%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_car_siren)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_car_siren[results_df_car_siren['Predicted Label'] == '차량사이렌'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'차량사이렌' Count: {etc_noise_count}\")\n",
    "print(f\"'차량사이렌' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb0f8f",
   "metadata": {},
   "source": [
    "### 차량 경적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b32ebd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189/3189 [05:27<00:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification completed. Results saved to 'car_horn.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/raw_data/1.Car/1.horn_of_car\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_car_horn = pd.DataFrame(results)\n",
    "results_df_car_horn.to_csv(\"car_horn.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'car_horn.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38c08578-d1e9-4b49-850f-0a29d6adf05d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "차량경적      3157\n",
       "이륜차경적       16\n",
       "이륜차주행음      11\n",
       "차량사이렌        2\n",
       "기타소음         2\n",
       "차량주행음        1\n",
       "Name: Predicted Label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df_car_horn['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02e07bba-73fb-40bd-b73c-ed7f8e5740c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Files: 3189\n",
      "'차량경적' Count: 3157\n",
      "'차량경적' Ratio: 99.00%\n"
     ]
    }
   ],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_car_horn)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_car_horn[results_df_car_horn['Predicted Label'] == '차량경적'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'차량경적' Count: {etc_noise_count}\")\n",
    "print(f\"'차량경적' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a5d0b-8336-4e1c-be05-0b3f3090b1e1",
   "metadata": {},
   "source": [
    "### 차량 주행음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb8e9ae-f896-48f4-8fb3-1b1f3872ca23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 73/227 [00:09<00:21,  7.31it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-14e2058a6612>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassify_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"File\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Predicted Label\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredicted_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-576d0503e060>\u001b[0m in \u001b[0;36mclassify_audio\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# 예측 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mpredicted_label_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredicted_label_encoded\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1745\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1747\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    717\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 719\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 3121\u001b[0;31m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[0m\u001b[1;32m   3122\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3123\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "folder_path = \"/home/ubuntu/data/test_data/raw_data_test/1.Car/3.driving_sound_of_car\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_car_driving = pd.DataFrame(results)\n",
    "results_df_car_driving.to_csv(\"car_driving.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'car_driving.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1170284e-cb3d-42dd-8456-d6431b3c428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_car_driving['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9772b060-f761-4ac8-a4ac-12d087e7289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_car_driving)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_car_driving[results_df_car_driving['Predicted Label'] == '차량주행음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'차량주행음' Count: {etc_noise_count}\")\n",
    "print(f\"'차량주행음' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe461b9-ed12-4360-a937-4119060654ab",
   "metadata": {},
   "source": [
    "### 이륜차 경적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2add6-39d9-4f00-a34e-865b2701b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/ubuntu/data/test_data/raw_data_test/2.Motorcycle/4.horn_of_motorcycle\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_motorcycle_horn = pd.DataFrame(results)\n",
    "results_df_motorcycle_horn.to_csv(\"motorcycle_horn.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'motorcycle_horn.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb240be-bb65-450a-a998-0b5e90ce6df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_motorcycle_horn['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c888d-ab95-4692-8561-fc98b2dbfbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_motorcycle_horn)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_motorcycle_horn[results_df_motorcycle_horn['Predicted Label'] == '이륜차경적'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'이륜차경적' Count: {etc_noise_count}\")\n",
    "print(f\"'이륜차경적' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345929e-69f5-4375-8d2d-a74a3046f154",
   "metadata": {},
   "source": [
    "### 이륜차 주행음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b7294-918c-42c4-a668-bacaed714c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/ubuntu/data/test_data/raw_data_test/2.Motorcycle/5.driving_sound_of_motorcycle\"\n",
    "results = []\n",
    "\n",
    "for filename in tqdm(os.listdir(folder_path)):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        predicted_label = classify_audio(file_path)\n",
    "        results.append({\"File\": filename, \"Predicted Label\": predicted_label})\n",
    "\n",
    "# 5. 결과를 DataFrame으로 변환하고 CSV로 저장\n",
    "results_df_motorcycle_driving = pd.DataFrame(results)\n",
    "results_df_motorcycle_driving.to_csv(\"motorcycle_driving.csv\", index=False)\n",
    "print(\"Classification completed. Results saved to 'motorcycle_driving.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ff1c90-fc34-4e56-8cd5-05655656f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_motorcycle_driving['Predicted Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24bd1cc-3c1f-4f6e-b57e-a01a4ff2998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '기타소음'의 개수와 비율 계산\n",
    "total_files = len(results_df_motorcycle_driving)  # 전체 파일 개수\n",
    "etc_noise_count = results_df_motorcycle_driving[results_df_motorcycle_driving['Predicted Label'] == '이륜차주행음'].shape[0]  # '기타소음'으로 분류된 파일 개수\n",
    "etc_noise_ratio = (etc_noise_count / total_files) * 100  # 비율 계산\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"Total Files: {total_files}\")\n",
    "print(f\"'이륜차주행음' Count: {etc_noise_count}\")\n",
    "print(f\"'이륜차주행음' Ratio: {etc_noise_ratio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea947a-66c7-4515-abd7-00b79a3736d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(ml_env_python3.6)",
   "language": "python",
   "name": "ml_env_python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
